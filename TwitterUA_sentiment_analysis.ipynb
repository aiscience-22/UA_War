{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c868192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import scipy \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "674ac08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cw/wcg51kjd6qvc1klqs9sykxb40000gn/T/ipykernel_7340/303370205.py:3: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  eng_df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# Data loading \n",
    "file_path = \"/Users/olgapodolska/Desktop/UA_War_my/resources/aug_twitter_data_cleaned.csv\"\n",
    "eng_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8772a294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>totaltweets</th>\n",
       "      <th>usercreatedts</th>\n",
       "      <th>tweetcreatedts</th>\n",
       "      <th>retweetcount</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>language</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>extractedts</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>3362</td>\n",
       "      <td>71331</td>\n",
       "      <td>2011-09-08 02:34:54.000000</td>\n",
       "      <td>2022-08-01 00:00:00.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>The #RussiaUkraine conflict is being cast in b...</td>\n",
       "      <td>[{'text': 'RussiaUkraine', 'indices': [4, 18]}...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-08-01 02:30:13.601013</td>\n",
       "      <td>the conflict is being cast in binaries making ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2964</td>\n",
       "      <td>4669</td>\n",
       "      <td>119795</td>\n",
       "      <td>2017-07-06 15:28:29.000000</td>\n",
       "      <td>2022-08-01 00:00:00.000000</td>\n",
       "      <td>560</td>\n",
       "      <td>Remember when #NATO smashed #Yugoslavia into s...</td>\n",
       "      <td>[{'text': 'NATO', 'indices': [14, 19]}, {'text...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-08-01 02:30:13.573250</td>\n",
       "      <td>remember when smashed into seven fragments and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>112</td>\n",
       "      <td>2021-04-04 17:47:00.000000</td>\n",
       "      <td>2022-08-01 00:00:01.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi #NATO , you have to understand that we are ...</td>\n",
       "      <td>[{'text': 'NATO', 'indices': [3, 8]}]</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-08-01 06:59:10.496078</td>\n",
       "      <td>hi  you have to understand that we are billion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137</td>\n",
       "      <td>114789</td>\n",
       "      <td>315096</td>\n",
       "      <td>2010-08-20 11:19:22.000000</td>\n",
       "      <td>2022-08-01 00:00:01.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>The world is in dire straits as it is not equi...</td>\n",
       "      <td>[{'text': 'UkraineCrisis', 'indices': [133, 14...</td>\n",
       "      <td>en</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-08-01 01:44:58.884242</td>\n",
       "      <td>the world is in dire straits as it is not equi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>3059</td>\n",
       "      <td>13665</td>\n",
       "      <td>2017-01-06 10:17:40.000000</td>\n",
       "      <td>2022-08-01 00:00:01.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Will the #sanctions imposed on #Russia cause a...</td>\n",
       "      <td>[{'text': 'sanctions', 'indices': [9, 19]}, {'...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-08-01 05:13:47.957650</td>\n",
       "      <td>will the imposed on cause a significant shift ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  following followers totaltweets               usercreatedts  \\\n",
       "0        51      3362       71331  2011-09-08 02:34:54.000000   \n",
       "1      2964      4669      119795  2017-07-06 15:28:29.000000   \n",
       "2        49         8         112  2021-04-04 17:47:00.000000   \n",
       "3       137    114789      315096  2010-08-20 11:19:22.000000   \n",
       "4        27      3059       13665  2017-01-06 10:17:40.000000   \n",
       "\n",
       "               tweetcreatedts retweetcount  \\\n",
       "0  2022-08-01 00:00:00.000000            0   \n",
       "1  2022-08-01 00:00:00.000000          560   \n",
       "2  2022-08-01 00:00:01.000000            0   \n",
       "3  2022-08-01 00:00:01.000000            0   \n",
       "4  2022-08-01 00:00:01.000000            0   \n",
       "\n",
       "                                                text  \\\n",
       "0  The #RussiaUkraine conflict is being cast in b...   \n",
       "1  Remember when #NATO smashed #Yugoslavia into s...   \n",
       "2  Hi #NATO , you have to understand that we are ...   \n",
       "3  The world is in dire straits as it is not equi...   \n",
       "4  Will the #sanctions imposed on #Russia cause a...   \n",
       "\n",
       "                                            hashtags language  favorite_count  \\\n",
       "0  [{'text': 'RussiaUkraine', 'indices': [4, 18]}...       en             0.0   \n",
       "1  [{'text': 'NATO', 'indices': [14, 19]}, {'text...       en             0.0   \n",
       "2              [{'text': 'NATO', 'indices': [3, 8]}]       en             0.0   \n",
       "3  [{'text': 'UkraineCrisis', 'indices': [133, 14...       en             1.0   \n",
       "4  [{'text': 'sanctions', 'indices': [9, 19]}, {'...       en             0.0   \n",
       "\n",
       "  is_retweet is_quote_status                 extractedts  \\\n",
       "0      False           False  2022-08-01 02:30:13.601013   \n",
       "1       True           False  2022-08-01 02:30:13.573250   \n",
       "2      False           False  2022-08-01 06:59:10.496078   \n",
       "3      False           False  2022-08-01 01:44:58.884242   \n",
       "4      False           False  2022-08-01 05:13:47.957650   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  the conflict is being cast in binaries making ...  \n",
       "1  remember when smashed into seven fragments and...  \n",
       "2  hi  you have to understand that we are billion...  \n",
       "3  the world is in dire straits as it is not equi...  \n",
       "4  will the imposed on cause a significant shift ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 5 rows of the august dataframe\n",
    "eng_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f96f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1255638 rows and 14 columns\n"
     ]
    }
   ],
   "source": [
    "# get shape of the DataFrame\n",
    "print(f\"{eng_df.shape[0]} rows and {eng_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee348ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1255638 entries, 0 to 1255637\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   following        1124566 non-null  object \n",
      " 1   followers        1124506 non-null  object \n",
      " 2   totaltweets      1124506 non-null  object \n",
      " 3   usercreatedts    1124506 non-null  object \n",
      " 4   tweetcreatedts   1124506 non-null  object \n",
      " 5   retweetcount     1124506 non-null  object \n",
      " 6   text             1124506 non-null  object \n",
      " 7   hashtags         1050085 non-null  object \n",
      " 8   language         1050058 non-null  object \n",
      " 9   favorite_count   1050058 non-null  float64\n",
      " 10  is_retweet       1050058 non-null  object \n",
      " 11  is_quote_status  1050058 non-null  object \n",
      " 12  extractedts      1050058 non-null  object \n",
      " 13  cleaned_text     1049977 non-null  object \n",
      "dtypes: float64(1), object(13)\n",
      "memory usage: 134.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "eng_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122ddf8",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9110c39f",
   "metadata": {},
   "source": [
    "For each tweet the RoBERTa model will generate a score for each of negative, neutral, and positive sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f43965da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8b6fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e15381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Create instance of twitter-roberta-base-sentiment classification model\n",
    "#model = AutoModel.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb2e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach it to the cuda\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c44c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import csv\n",
    "\n",
    "labels=[] # will contain 'positive', 'neutral', 'negative'\n",
    "task = 'sentiment' # our task is sentiment analysis\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96df755e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'neutral', 'positive']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "227d5675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12557 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "  0%|          | 57/12557 [17:01<62:14:01, 17.92s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/olgapodolska/Desktop/UA_War/TwitterUA_sentiment_analysis.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/olgapodolska/Desktop/UA_War/TwitterUA_sentiment_analysis.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m end_idx \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(start_idx \u001b[39m+\u001b[39m BATCH_SIZE, n) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/olgapodolska/Desktop/UA_War/TwitterUA_sentiment_analysis.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# reference: https://huggingface.co/docs/transformers/preprocessing\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/olgapodolska/Desktop/UA_War/TwitterUA_sentiment_analysis.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# tokenize the tweets in the batch, return pytorch ('pt') tensors\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/olgapodolska/Desktop/UA_War/TwitterUA_sentiment_analysis.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# some tweets are shorter than the uniform tensor length needed; padding adds 0's to maintain uniform tensor length\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/olgapodolska/Desktop/UA_War/TwitterUA_sentiment_analysis.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# some tweets are too long; truncation truncates input to maximum length accepted by model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/olgapodolska/Desktop/UA_War/TwitterUA_sentiment_analysis.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m encoded_input \u001b[39m=\u001b[39m tokenizer(text_all[start_idx:end_idx], return_tensors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m'\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/olgapodolska/Desktop/UA_War/TwitterUA_sentiment_analysis.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# references: https://stackoverflow.com/questions/11315010/what-do-and-before-a-variable-name-mean-in-a-function-signature\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/olgapodolska/Desktop/UA_War/TwitterUA_sentiment_analysis.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# https://stackoverflow.com/questions/1419046/normal-arguments-vs-keyword-arguments/1419160#1419160\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/olgapodolska/Desktop/UA_War/TwitterUA_sentiment_analysis.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m output \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mencoded_input)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aiscience/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2455\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2452\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch length of `text`: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text)\u001b[39m}\u001b[39;00m\u001b[39m does not match batch length of `text_pair`: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text_pair)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2453\u001b[0m         )\n\u001b[1;32m   2454\u001b[0m     batch_text_or_text_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(text, text_pair)) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m text\n\u001b[0;32m-> 2455\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_encode_plus(\n\u001b[1;32m   2456\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2457\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2458\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m   2459\u001b[0m         truncation\u001b[39m=\u001b[39;49mtruncation,\n\u001b[1;32m   2460\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2461\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2462\u001b[0m         is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2463\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2464\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2465\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2466\u001b[0m         return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2467\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2468\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2469\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2470\u001b[0m         return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2471\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2472\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2473\u001b[0m     )\n\u001b[1;32m   2474\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2475\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[1;32m   2476\u001b[0m         text\u001b[39m=\u001b[39mtext,\n\u001b[1;32m   2477\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2493\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2494\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aiscience/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2646\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2636\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2637\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2638\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   2639\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2643\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2644\u001b[0m )\n\u001b[0;32m-> 2646\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_encode_plus(\n\u001b[1;32m   2647\u001b[0m     batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2648\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2649\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[1;32m   2650\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[1;32m   2651\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2652\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2653\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2654\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2655\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2656\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2657\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2658\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2659\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2660\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2661\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2662\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2663\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2664\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aiscience/lib/python3.10/site-packages/transformers/models/roberta/tokenization_roberta_fast.py:254\u001b[0m, in \u001b[0;36mRobertaTokenizerFast._batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m is_split_into_words \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mis_split_into_words\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    249\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_prefix_space \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    250\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou need to instantiate \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m with add_prefix_space=True \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mto use it with pretokenized inputs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m )\n\u001b[0;32m--> 254\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_batch_encode_plus(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aiscience/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:425\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_truncation_and_padding(\n\u001b[1;32m    418\u001b[0m     padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[1;32m    419\u001b[0m     truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m    423\u001b[0m )\n\u001b[0;32m--> 425\u001b[0m encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenizer\u001b[39m.\u001b[39;49mencode_batch(\n\u001b[1;32m    426\u001b[0m     batch_text_or_text_pairs,\n\u001b[1;32m    427\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m    428\u001b[0m     is_pretokenized\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m    429\u001b[0m )\n\u001b[1;32m    431\u001b[0m \u001b[39m# Convert encoding to dict\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[39m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[39m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m#                       List[EncodingFast]\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m#                    ]\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[1;32m    437\u001b[0m tokens_and_encodings \u001b[39m=\u001b[39m [\n\u001b[1;32m    438\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_encoding(\n\u001b[1;32m    439\u001b[0m         encoding\u001b[39m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[39mfor\u001b[39;00m encoding \u001b[39min\u001b[39;00m encodings\n\u001b[1;32m    449\u001b[0m ]\n",
      "\u001b[0;31mTypeError\u001b[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 100 # number of tweets in a batch that will be passed into tokenizer\n",
    "\n",
    "scores_all = np.empty((0,len(labels)))\n",
    "# create list of all the tweets in the dataset\n",
    "text_all = eng_df['cleaned_text'].to_list()\n",
    "n = len(text_all) # same as number of tweets\n",
    "with torch.no_grad():\n",
    "    for start_idx in tqdm(range(0, n, BATCH_SIZE)):\n",
    "        end_idx = min(start_idx + BATCH_SIZE, n) \n",
    "        # reference: https://huggingface.co/docs/transformers/preprocessing\n",
    "        # tokenize the tweets in the batch, return pytorch ('pt') tensors\n",
    "        # some tweets are shorter than the uniform tensor length needed; padding adds 0's to maintain uniform tensor length\n",
    "        # some tweets are too long; truncation truncates input to maximum length accepted by model\n",
    "        encoded_input = tokenizer(text_all[start_idx:end_idx], return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "        \n",
    "        # references: https://stackoverflow.com/questions/11315010/what-do-and-before-a-variable-name-mean-in-a-function-signature\n",
    "        # https://stackoverflow.com/questions/1419046/normal-arguments-vs-keyword-arguments/1419160#1419160\n",
    "        output = model(**encoded_input)\n",
    "        # convert pytorch tensor to numpy\n",
    "        scores = output[0].detach().cpu().numpy()\n",
    "        # \n",
    "        scores = softmax(scores, axis=1)\n",
    "        scores_all = np.concatenate((scores_all, scores), axis=0)\n",
    "        \n",
    "        # delete encoded_input, output, scores for next batch\n",
    "        del encoded_input, output, scores \n",
    "        # release all unoccupied cached mem \n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d507c999",
   "metadata": {},
   "source": [
    "Output below is what scores_all looks like. Each row contains scores for negative, neutral, and positive sentiments. The higher the score, the more likely the tweet has that sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095054a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70771761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's combine the scores with the existing DataFrame.\n",
    "eng_df[labels] = pd.DataFrame(scores_all, columns=labels)\n",
    "eng_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d7319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c7bc675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this DataFrame so that we don't have to run the model again, which takes a long time.\n",
    "file_path = \"resources/aug_twitter_sentiments.csv\"\n",
    "eng_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4decbdf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('aiscience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d10dae41f6ce83c02c9a0f4de5bf9680e40d465e2a68013470b1e083b1c4c0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
