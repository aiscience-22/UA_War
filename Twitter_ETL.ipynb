{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter ETL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+PsUGaiXEKnupNRhFqkt9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aiscience-22/UA_War/blob/machine_learning_0.03/Twitter_ETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI18fPxxmjnQ",
        "outputId": "3d62ef32-28ee-4e99-a2bd-27ba4f60358a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (65.9.86.28)] [Conne\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connected to cloud.r-proje\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connected to cloud.r-proje\r                                                                               \rHit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connected to cloud.r-proje\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "\r                                                                               \r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers]\r                                                                         \rHit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "\r                                                                         \r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers]\r                                                   \rHit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.2.2'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a Postgres driver that will allow Spark to interact with Postgres\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkfNAMO0oyhV",
        "outputId": "9497246c-d181-4e8f-d424-0e0c507479bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-30 22:59:41--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.16.jar’\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  1.59MB/s    in 0.6s    \n",
            "\n",
            "2022-08-30 22:59:42 (1.59 MB/s) - ‘postgresql-42.2.16.jar’ saved [1002883/1002883]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rHUH3ek31O04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add drivers to Spark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"CloudETL\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
      ],
      "metadata": {
        "id": "nmUzedI5pE-9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9g3t5mdrpVYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://uaresources.s3.us-west-1.amazonaws.com/twitter_sentiments.csv\"\n",
        "\n",
        "spark.sparkContext.addFile(url)\n",
        "text_df = spark.read.csv(SparkFiles.get(\"twitter_sentiments.csv\"), sep=\",\", header=True, inferSchema=True)\n",
        "\n",
        "\n",
        "# Show DataFrame\n",
        "text_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPz78NoiqQ44",
        "outputId": "08cb7e31-7d38-472a-e42b-3e5044f251e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+-----------+--------------------+-------------------+------------+--------------------+--------+--------------+----------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|following|followers|totaltweets|       usercreatedts|     tweetcreatedts|retweetcount|            hashtags|language|favorite_count|is_retweet|is_quote_status|         extractedts|        cleaned_text|            negative|             neutral|            positive|\n",
            "+---------+---------+-----------+--------------------+-------------------+------------+--------------------+--------+--------------+----------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|       51|     3362|      71331|2011-09-08 02:34:...|2022-08-01 00:00:00|           0|[{'text': 'Russia...|      en|           0.0|     false|          false|2022-08-01 02:30:...|the conflict is b...|  0.6027117371559143|  0.3816339075565338|  0.0156544279307127|\n",
            "|      137|   114789|     315096|2010-08-20 11:19:...|2022-08-01 00:00:01|           0|[{'text': 'Ukrain...|      en|           1.0|     false|          false|2022-08-01 01:44:...|the world is in d...|  0.8760229349136353| 0.11690667271614075|0.007070484571158886|\n",
            "|     7284|     6963|     264990|2009-06-07 05:36:...|2022-08-01 00:00:01|           0|[{'text': 'Ukrain...|      en|           1.0|     false|          false|2022-08-01 02:36:...|owner of ukraines...|  0.8333819508552551| 0.16298656165599823|0.003631420433521...|\n",
            "|     1080|    14429|      35346|2013-05-11 18:28:...|2022-08-01 00:00:02|           1|[{'text': 'Iran',...|      en|           2.0|     false|          false|2022-08-01 05:13:...|why  relations li...|  0.4097643494606018|  0.5677175521850586|0.022518066689372063|\n",
            "|     1980|     1827|      67996|2007-03-23 21:01:...|2022-08-01 00:00:02|           1|[{'text': 'ToryFa...|      en|           0.0|      true|           true|2022-08-01 02:36:...|its happening on ...| 0.06149579584598541|  0.8488444089889526| 0.08965984731912613|\n",
            "|      421|       87|       6591|2013-07-09 15:55:...|2022-08-01 00:00:03|           0|[{'text': 'kosovo...|      en|           0.0|     false|          false|2022-08-01 00:29:...|serbian vucic is ...|  0.9745429158210754|0.023634416982531548|0.001822606194764...|\n",
            "|      478|      163|       6760|2014-12-26 00:31:...|2022-08-01 00:00:08|          76|[{'text': 'Ukrain...|      en|           0.0|      true|          false|2022-08-01 02:30:...|russian rocket ki...|  0.9219619035720825| 0.07327494770288467|0.004763160366564989|\n",
            "|      155|       15|      16148|2014-07-29 13:13:...|2022-08-01 00:00:09|         282|[{'text': 'Russia...|      en|           0.0|      true|          false|2022-08-01 00:51:...|legion freedom of...|  0.0326119139790535|  0.9228765368461609| 0.04451160877943039|\n",
            "|     5001|     1912|     163860|2012-06-23 01:23:...|2022-08-01 00:00:10|         454|[{'text': 'sancti...|      en|           0.0|      true|          false|2022-08-01 00:51:...|are italian compa...|  0.2644941508769989|  0.6772770285606384|  0.0582287460565567|\n",
            "|      478|       59|      34296|2009-10-19 22:54:...|2022-08-01 00:00:10|          43|[{'text': 'Ukrain...|      en|           0.0|      true|          false|2022-08-01 01:44:...|turkey refused ru...|  0.5558522343635559|  0.4350818991661072|0.009065911173820496|\n",
            "|     5001|     1365|      77636|2014-01-03 09:33:...|2022-08-01 00:00:11|          29|[{'text': 'Ukrain...|      en|           0.0|      true|          false|2022-08-01 02:36:...|zelensky formal l...| 0.15101107954978943|  0.7638165354728699|  0.0851723775267601|\n",
            "|       74|     1543|         23|2011-01-12 05:49:...|2022-08-01 00:00:19|        1052|[{'text': 'Oleniv...|      en|           0.0|      true|          false|2022-08-01 00:06:...|i condemn brutal ...|  0.9047191143035889| 0.09236498177051544|0.002915868535637...|\n",
            "|      746|      442|      24758|2009-06-04 14:09:...|2022-08-01 00:00:21|           8|[{'text': 'Russia...|      en|           0.0|      true|          false|2022-08-01 01:44:...| a new video of a...|0.042681001126766205|  0.9255278706550598| 0.03179115802049637|\n",
            "|     1330|      306|       2011|2009-01-12 17:56:...|2022-08-01 00:00:24|         384|[{'text': 'Ukrain...|      en|           0.0|      true|          false|2022-08-01 01:44:...|good night world ...|0.002705698134377...| 0.06929384917020798|  0.9280004501342773|\n",
            "|      383|       50|       9707|2010-09-13 16:18:...|2022-08-01 00:00:29|          25|[{'text': 'Kosovo...|      en|           0.0|      true|          false|2022-08-01 00:29:...|support for kosov...| 0.10012583434581757| 0.49994635581970215| 0.39992785453796387|\n",
            "|     4990|      565|      83755|2012-06-11 17:01:...|2022-08-01 00:00:35|         235|[{'text': 'ActOnC...|      en|           0.0|      true|          false|2022-08-01 02:36:...|reminder russia c...|  0.8852719664573669| 0.11040213704109192|0.004325922578573227|\n",
            "|      804|      340|      35100|2011-11-16 19:45:...|2022-08-01 00:00:45|         276|[{'text': 'Faroes...|      en|           0.0|      true|          false|2022-08-01 00:51:...|this kills me a b...|  0.9716231822967529|0.026602070778608322|0.001774684293195...|\n",
            "|      184|      151|        251|2013-08-28 12:23:...|2022-08-01 00:00:46|           0|[{'text': 'Kosovo...|      en|           1.0|     false|          false|2022-08-01 00:29:...|why are you choos...|  0.3273519277572632|  0.6276887059211731| 0.04495938494801521|\n",
            "|     2031|     2051|     106112|2014-03-14 17:16:...|2022-08-01 00:00:48|         384|[{'text': 'Ukrain...|      en|           0.0|      true|          false|2022-08-01 01:44:...|good night world ...|0.002705698134377...| 0.06929384917020798|  0.9280004501342773|\n",
            "|       59|      187|      21958|2013-02-12 03:01:...|2022-08-01 00:00:51|        1315|[{'text': 'StandW...|      en|           0.0|      true|          false|2022-08-01 02:36:...|today prime minis...|0.018899668008089066| 0.25686609745025635|  0.7242342233657837|\n",
            "+---------+---------+-----------+--------------------+-------------------+------------+--------------------+--------+--------------+----------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop null values\n",
        "text_df=text_df.dropna()\n",
        "text_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-U8760X1_Up",
        "outputId": "b324f7c0-809b-4d05-e854-10f147684c97"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+-----------+--------------------+-------------------+------------+--------------------+--------+--------------+----------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|following|followers|totaltweets|       usercreatedts|     tweetcreatedts|retweetcount|            hashtags|language|favorite_count|is_retweet|is_quote_status|         extractedts|        cleaned_text|            negative|             neutral|            positive|\n",
            "+---------+---------+-----------+--------------------+-------------------+------------+--------------------+--------+--------------+----------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|       51|     3362|      71331|2011-09-08 02:34:...|2022-08-01 00:00:00|           0|[{'text': 'Russia...|      en|           0.0|     false|          false|2022-08-01 02:30:...|the conflict is b...|  0.6027117371559143|  0.3816339075565338|  0.0156544279307127|\n",
            "|      137|   114789|     315096|2010-08-20 11:19:...|2022-08-01 00:00:01|           0|[{'text': 'Ukrain...|      en|           1.0|     false|          false|2022-08-01 01:44:...|the world is in d...|  0.8760229349136353| 0.11690667271614075|0.007070484571158886|\n",
            "|     7284|     6963|     264990|2009-06-07 05:36:...|2022-08-01 00:00:01|           0|[{'text': 'Ukrain...|      en|           1.0|     false|          false|2022-08-01 02:36:...|owner of ukraines...|  0.8333819508552551| 0.16298656165599823|0.003631420433521...|\n",
            "|     1080|    14429|      35346|2013-05-11 18:28:...|2022-08-01 00:00:02|           1|[{'text': 'Iran',...|      en|           2.0|     false|          false|2022-08-01 05:13:...|why  relations li...|  0.4097643494606018|  0.5677175521850586|0.022518066689372063|\n",
            "|     1980|     1827|      67996|2007-03-23 21:01:...|2022-08-01 00:00:02|           1|[{'text': 'ToryFa...|      en|           0.0|      true|           true|2022-08-01 02:36:...|its happening on ...| 0.06149579584598541|  0.8488444089889526| 0.08965984731912613|\n",
            "|      421|       87|       6591|2013-07-09 15:55:...|2022-08-01 00:00:03|           0|[{'text': 'kosovo...|      en|           0.0|     false|          false|2022-08-01 00:29:...|serbian vucic is ...|  0.9745429158210754|0.023634416982531548|0.001822606194764...|\n",
            "|      478|      163|       6760|2014-12-26 00:31:...|2022-08-01 00:00:08|          76|[{'text': 'Ukrain...|      en|           0.0|      true|          false|2022-08-01 02:30:...|russian rocket ki...|  0.9219619035720825| 0.07327494770288467|0.004763160366564989|\n",
            "|      155|       15|      16148|2014-07-29 13:13:...|2022-08-01 00:00:09|         282|[{'text': 'Russia...|      en|           0.0|      true|          false|2022-08-01 00:51:...|legion freedom of...|  0.0326119139790535|  0.9228765368461609| 0.04451160877943039|\n",
            "|     5001|     1912|     163860|2012-06-23 01:23:...|2022-08-01 00:00:10|         454|[{'text': 'sancti...|      en|           0.0|      true|          false|2022-08-01 00:51:...|are italian compa...|  0.2644941508769989|  0.6772770285606384|  0.0582287460565567|\n",
            "|      478|       59|      34296|2009-10-19 22:54:...|2022-08-01 00:00:10|          43|[{'text': 'Ukrain...|      en|           0.0|      true|          false|2022-08-01 01:44:...|turkey refused ru...|  0.5558522343635559|  0.4350818991661072|0.009065911173820496|\n",
            "|     5001|     1365|      77636|2014-01-03 09:33:...|2022-08-01 00:00:11|          29|[{'text': 'Ukrain...|      en|           0.0|      true|          false|2022-08-01 02:36:...|zelensky formal l...| 0.15101107954978943|  0.7638165354728699|  0.0851723775267601|\n",
            "|       74|     1543|         23|2011-01-12 05:49:...|2022-08-01 00:00:19|        1052|[{'text': 'Oleniv...|      en|           0.0|      true|          false|2022-08-01 00:06:...|i condemn brutal ...|  0.9047191143035889| 0.09236498177051544|0.002915868535637...|\n",
            "|      746|      442|      24758|2009-06-04 14:09:...|2022-08-01 00:00:21|           8|[{'text': 'Russia...|      en|           0.0|      true|          false|2022-08-01 01:44:...| a new video of a...|0.042681001126766205|  0.9255278706550598| 0.03179115802049637|\n",
            "|     1330|      306|       2011|2009-01-12 17:56:...|2022-08-01 00:00:24|         384|[{'text': 'Ukrain...|      en|           0.0|      true|          false|2022-08-01 01:44:...|good night world ...|0.002705698134377...| 0.06929384917020798|  0.9280004501342773|\n",
            "|      383|       50|       9707|2010-09-13 16:18:...|2022-08-01 00:00:29|          25|[{'text': 'Kosovo...|      en|           0.0|      true|          false|2022-08-01 00:29:...|support for kosov...| 0.10012583434581757| 0.49994635581970215| 0.39992785453796387|\n",
            "|     4990|      565|      83755|2012-06-11 17:01:...|2022-08-01 00:00:35|         235|[{'text': 'ActOnC...|      en|           0.0|      true|          false|2022-08-01 02:36:...|reminder russia c...|  0.8852719664573669| 0.11040213704109192|0.004325922578573227|\n",
            "|      804|      340|      35100|2011-11-16 19:45:...|2022-08-01 00:00:45|         276|[{'text': 'Faroes...|      en|           0.0|      true|          false|2022-08-01 00:51:...|this kills me a b...|  0.9716231822967529|0.026602070778608322|0.001774684293195...|\n",
            "|      184|      151|        251|2013-08-28 12:23:...|2022-08-01 00:00:46|           0|[{'text': 'Kosovo...|      en|           1.0|     false|          false|2022-08-01 00:29:...|why are you choos...|  0.3273519277572632|  0.6276887059211731| 0.04495938494801521|\n",
            "|     2031|     2051|     106112|2014-03-14 17:16:...|2022-08-01 00:00:48|         384|[{'text': 'Ukrain...|      en|           0.0|      true|          false|2022-08-01 01:44:...|good night world ...|0.002705698134377...| 0.06929384917020798|  0.9280004501342773|\n",
            "|       59|      187|      21958|2013-02-12 03:01:...|2022-08-01 00:00:51|        1315|[{'text': 'StandW...|      en|           0.0|      true|          false|2022-08-01 02:36:...|today prime minis...|0.018899668008089066| 0.25686609745025635|  0.7242342233657837|\n",
            "+---------+---------+-----------+--------------------+-------------------+------------+--------------------+--------+--------------+----------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data types\n",
        "text_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "LK4QtqyLE1QB",
        "outputId": "cf019043-e2a9-4244-bda6-2108829e182c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-03c9be5630e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check data types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtext_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1660\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1661\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'info'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the dtypes of usercreatedts, tweetcreatedts, and extractedts to datetime64 for easier operation later\n",
        "text_df[\"usercreatedts\"] = pd.to_datetime(text_df[\"usercreatedts\"])\n",
        "text_df[\"tweetcreatedts\"] = pd.to_datetime(text_df[\"tweetcreatedts\"])\n",
        "text_df[\"extractedts\"] = pd.to_datetime(text_df[\"extractedts\"])\n",
        "\n",
        "# check dtypes\n",
        "text_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "yfU2C-QeGGPM",
        "outputId": "b06af9be-ad4e-45ca-8f6a-1ce87ad64013"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-fabe092c99d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Change the dtypes of usercreatedts, tweetcreatedts, and extractedts to datetime64 for easier operation later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtext_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usercreatedts\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usercreatedts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtext_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tweetcreatedts\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tweetcreatedts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtext_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extractedts\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extractedts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    880\u001b[0m                 \u001b[0;31m# error: Too many arguments for \"tz_localize\" of \"NaTType\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mcache_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_typ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"__instancecheck__\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__subclasscheck__\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop2.7/python/pyspark/sql/column.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         raise ValueError(\"Cannot convert column into bool: please use '&' for 'and', '|' for 'or', \"\n\u001b[0m\u001b[1;32m    908\u001b[0m                          \"'~' for 'not' when building DataFrame boolean expressions.\")\n\u001b[1;32m    909\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize tweet sentiment by date\n",
        "# get dates in the dataframe \n",
        "dates = text_df[\"tweetcreatedts\"].dt.day\n",
        "# group tweet timestamps by date and get average negative score for each date\n",
        "negative_by_date = text_df[[\"tweetcreatedts\", \"negative\"]].groupby(dates).avg('negative')\n",
        "\n",
        "# plot bar graph of tweet count by date\n",
        "negative_by_date.plot.line();\n",
        "\n",
        "plt.title(\"Negative Tweet Sentiments by Date\")\n",
        "plt.xlabel(\"Tweet Date\")\n",
        "plt.ylabel(\"Negative Sentiment\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "1Gq6wr3tCWSH",
        "outputId": "362ca3c1-3ae6-41a9-cda8-52445f3a1d2b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b148f2e03028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tweetcreatedts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# group tweet timestamps by date and get average negative score for each date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnegative_by_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tweetcreatedts\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"negative\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'negative'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# plot bar graph of tweet count by date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop2.7/python/pyspark/sql/group.py\u001b[0m in \u001b[0;36m_api\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop2.7/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: Can't extract value from tweetcreatedts#149: need struct type but got string"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get our transformed raw data into our database**"
      ],
      "metadata": {
        "id": "ATojnogKLDl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store environmental variable\n",
        "from getpass import getpass\n",
        "password = getpass('password')\n",
        "# Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://tweets.cnzbbvrrhst7.us-west-1.rds.amazonaws.com:5432/postgres\"\n",
        "config = {\"user\":\"uatweets\",\n",
        "          \"password\": password,\n",
        "          \"driver\":\"org.postgresql.Driver\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3KZN-bpK51U",
        "outputId": "88d5c8b7-9214-4f87-bbcb-ed4668a13d2b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "password··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write DataFrame to active_user table in RDS\n",
        "text_df.write.jdbc(url=jdbc_url, table='twitter_sentiments.csv', mode=mode, properties=config)"
      ],
      "metadata": {
        "id": "7RciZsk5RSkb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "04084933-3932-48f3-9bfb-c6848e2df8dc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5001f81ae11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Write DataFrame to active_user table in RDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdropna_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'twitter_sentiments.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0mjprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop2.7/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop2.7/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o81.jdbc.\n: org.postgresql.util.PSQLException: ERROR: schema \"twitter_sentiments\" does not exist\n  Position: 14\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2553)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2285)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:323)\n\tat org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:473)\n\tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:393)\n\tat org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:322)\n\tat org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:308)\n\tat org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:284)\n\tat org.postgresql.jdbc.PgStatement.executeUpdate(PgStatement.java:258)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.executeStatement(JdbcUtils.scala:1031)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.createTable(JdbcUtils.scala:917)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:80)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:97)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:97)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:93)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:93)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:78)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:115)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:745)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4hQ3VVsBR4uE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}