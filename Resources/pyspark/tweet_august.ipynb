{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQPeAcH-160k",
        "outputId": "7691a50d-bad1-418f-e47c-464880d6070a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,534 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,939 kB]\n",
            "Get:15 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [91.1 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [912 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,093 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,073 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,369 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,311 kB]\n",
            "Fetched 14.6 MB in 5s (2,744 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "# Importing the libraries needed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import scipy \n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import logging\n",
        "import os\n",
        "# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.2.2'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53UT8GZe21J_",
        "outputId": "a7e30719-4fc8-461b-ec3b-4c39c06b6693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-30 03:51:54--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: â€˜postgresql-42.2.16.jarâ€™\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  6.04MB/s    in 0.2s    \n",
            "\n",
            "2022-08-30 03:51:54 (6.04 MB/s) - â€˜postgresql-42.2.16.jarâ€™ saved [1002883/1002883]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Mfy8zMU72vjc"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"UA_War\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYrfA-bu20FQ",
        "outputId": "1b500598-5752-4fd0-9a9b-fbad5c869c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+---------------+--------------------+--------------------+---------+---------+-----------+--------------------+-------------------+--------------------+------------+--------------------+--------------------+--------+-----------+--------------+----------+-------------------+---------------------+-----------------------+---------------------+-------------------+-----------------------+---------------+----------------+--------------------+----------------------+--------------------+\n",
            "|_c0|             userid|       username|            acctdesc|            location|following|followers|totaltweets|       usercreatedts|            tweetid|      tweetcreatedts|retweetcount|                text|            hashtags|language|coordinates|favorite_count|is_retweet|  original_tweet_id|original_tweet_userid|original_tweet_username|in_reply_to_status_id|in_reply_to_user_id|in_reply_to_screen_name|is_quote_status|quoted_status_id|quoted_status_userid|quoted_status_username|         extractedts|\n",
            "+---+-------------------+---------------+--------------------+--------------------+---------+---------+-----------+--------------------+-------------------+--------------------+------------+--------------------+--------------------+--------+-----------+--------------+----------+-------------------+---------------------+-----------------------+---------------------+-------------------+-----------------------+---------------+----------------+--------------------+----------------------+--------------------+\n",
            "|  0|          369869874|      ORFMumbai|Nonâ€“partisan, ind...|Nariman Point, Mu...|       51|     3362|      71331|2011-09-08 02:34:...|1553893270027063297|2022-08-01 00:00:...|           0|The #RussiaUkrain...|[{'text': 'Russia...|      en|    <empty>|             0|     false|                  0|                    0|                <empty>|                    0|                  0|                <empty>|          false|               0|                   0|               <empty>|2022-08-01 02:30:...|\n",
            "|  1| 882984605028102144|   For2000years|\"I have certain r...|         Facing East|     2964|     4669|     119795|2017-07-06 15:28:...|1553893270983409670|2022-08-01 00:00:...|         560|Remember when #NA...|[{'text': 'NATO',...|      en|    <empty>|             0|      true|1553864158285705216|             56575418|             timand2037|                    0|                  0|                <empty>|          false|               0|                   0|               <empty>|2022-08-01 02:30:...|\n",
            "|  2| 862842887565869056| CumanaCandanga|IG: @CumanaCandan...|   Cumana, Venezuela|     6033|     6730|      18870|2017-05-12 01:32:...|1553893271671382024|2022-08-01 00:00:...|          13|No es posible que...|[{'text': 'OTAN',...|      es|    <empty>|             0|      true|1553834180093661184|  1441312629155237888|        ProfeJesusDavid|                    0|                  0|                <empty>|          false|               0|                   0|               <empty>|2022-08-01 00:29:...|\n",
            "|  3|1366546460557385729|EnfoquesEnCorto|ðŸ“»Sigue nuestros ...|          Mexico, ME|      195|      192|      20780|2021-03-02 00:30:...|1553893273751666691|2022-08-01 00:00:...|           0|#Internacional Es...|[{'text': 'Intern...|      es|    <empty>|             1|     false|                  0|                    0|                <empty>|                    0|                  0|                <empty>|          false|               0|                   0|               <empty>|2022-08-01 10:29:...|\n",
            "|  4|1378766002792583168|    kaotiskhund|             <empty>|             <empty>|       49|        8|        112|2021-04-04 17:47:...|1553893274687094785|2022-08-01 00:00:...|           0|Hi #NATO , you ha...|[{'text': 'NATO',...|      en|    <empty>|             0|     false|                  0|                    0|                <empty>|                    0|                  0|                <empty>|          false|               0|                   0|               <empty>|2022-08-01 06:59:...|\n",
            "+---+-------------------+---------------+--------------------+--------------------+---------+---------+-----------+--------------------+-------------------+--------------------+------------+--------------------+--------------------+--------+-----------+--------------+----------+-------------------+---------------------+-----------------------+---------------------+-------------------+-----------------------+---------------+----------------+--------------------+----------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#import data from aws s3 bucket for 1 day. This will be the starting dataframe to populate DB\n",
        "\n",
        "from pyspark import SparkFiles\n",
        "start_date = \"0801\"\n",
        "\n",
        "url = f\"https://databootcamps3bucket.s3.us-west-2.amazonaws.com/ua_war/UkraineWar/{start_date}_UATweets.csv.gz\"\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "df_start_date = spark.read.option(\"delimiter\", \",\").option(\"encoding\", \"UTF-8\").option(\"multiLine\", True).option(\"escape\", '\"').csv(SparkFiles.get(f\"{start_date}_UATweets.csv.gz\"),  header=True, inferSchema=True)\n",
        "\n",
        "# df.show(truncate=False) \n",
        "df_start_date_2 = df_start_date.na.fill(\"<empty>\")\n",
        "\n",
        "df_start_date_2.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwCpQsor2vnS",
        "outputId": "8bc65f50-d8f2-4301-8442-3f7845123fa2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('_c0', 'int'),\n",
              " ('userid', 'bigint'),\n",
              " ('username', 'string'),\n",
              " ('acctdesc', 'string'),\n",
              " ('location', 'string'),\n",
              " ('following', 'int'),\n",
              " ('followers', 'int'),\n",
              " ('totaltweets', 'int'),\n",
              " ('usercreatedts', 'string'),\n",
              " ('tweetid', 'bigint'),\n",
              " ('tweetcreatedts', 'string'),\n",
              " ('retweetcount', 'int'),\n",
              " ('text', 'string'),\n",
              " ('hashtags', 'string'),\n",
              " ('language', 'string'),\n",
              " ('coordinates', 'string'),\n",
              " ('favorite_count', 'int'),\n",
              " ('is_retweet', 'boolean'),\n",
              " ('original_tweet_id', 'bigint'),\n",
              " ('original_tweet_userid', 'bigint'),\n",
              " ('original_tweet_username', 'string'),\n",
              " ('in_reply_to_status_id', 'bigint'),\n",
              " ('in_reply_to_user_id', 'bigint'),\n",
              " ('in_reply_to_screen_name', 'string'),\n",
              " ('is_quote_status', 'boolean'),\n",
              " ('quoted_status_id', 'bigint'),\n",
              " ('quoted_status_userid', 'bigint'),\n",
              " ('quoted_status_username', 'string'),\n",
              " ('extractedts', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#see what the datatypes for df_8018 \n",
        "df_start_date.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ba5yU10j4S9u",
        "outputId": "41fda0dd-0b2a-498c-e404-004570f2afe1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#use this to determine which type of drop is needed. Also not all all dates have same number of columns \n",
        "len(df_start_date.columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkFiles\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "#use this to determine which type of drop is needed. Also not all all dates have same number of columns \n",
        "df_start_date_count = len(df_start_date.columns)\n",
        "if df_start_date_count == 18:\n",
        "  df_start_date_2 = df_start_date_2.withColumn(\"is_retweet\", lit(None).cast('boolean')) \n",
        "  df_start_date_2 = df_start_date_2.withColumn(\"is_quote_status\", lit(None).cast('boolean')) \n",
        "\n",
        "len(df_start_date_2.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfJBYkO5VQA6",
        "outputId": "293d2096-d68a-4a4e-a64e-799652c031ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJWMS6ji65Lu",
        "outputId": "e1c1745b-32c7-4188-c8c0-33c0d623bf8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+\n",
            "|    username|following|followers|totaltweets|usercreatedts|tweetcreatedts|retweetcount|                text|            hashtags|language|favorite_count|is_retweet|is_quote_status|extractedts|\n",
            "+------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+\n",
            "|   ORFMumbai|       51|     3362|      71331|   2011-09-08|    2022-08-01|           0|The #RussiaUkrain...|[{'text': 'Russia...|      en|             0|     false|          false| 2022-08-01|\n",
            "|For2000years|     2964|     4669|     119795|   2017-07-06|    2022-08-01|         560|Remember when #NA...|[{'text': 'NATO',...|      en|             0|      true|          false| 2022-08-01|\n",
            "| kaotiskhund|       49|        8|        112|   2021-04-04|    2022-08-01|           0|Hi #NATO , you ha...|[{'text': 'NATO',...|      en|             0|     false|          false| 2022-08-01|\n",
            "|   orfonline|      137|   114789|     315096|   2010-08-20|    2022-08-01|           0|The world is in d...|[{'text': 'Ukrain...|      en|             1|     false|          false| 2022-08-01|\n",
            "|     orfecon|       27|     3059|      13665|   2017-01-06|    2022-08-01|           0|Will the #sanctio...|[{'text': 'sancti...|      en|             0|     false|          false| 2022-08-01|\n",
            "+------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "#1. Drop Uncessary Columns using the data set as a starting point. \n",
        "cleaned_df = df_start_date_2.drop(\"userid\", \"_c0\", \"acctdesc\", \"location\", \"tweetid\", \"coordinates\", \"original_tweet_id\", \"original_tweet_userid\", \"original_tweet_username\", \"in_reply_to_status_id\", \"in_reply_to_screen_name\", 'in_reply_to_user_id', \"quoted_status_id\", \"quoted_status_username\", \"quoted_status_userid\")\n",
        "\n",
        "#2. change columns from string to year:month:day date format\n",
        "cleaned_df = cleaned_df.withColumn(\"usercreatedts\",to_date(\"usercreatedts\"))\n",
        "cleaned_df = cleaned_df.withColumn(\"tweetcreatedts\",to_date(\"tweetcreatedts\"))\n",
        "cleaned_df = cleaned_df.withColumn(\"extractedts\",to_date(\"extractedts\"))\n",
        "\n",
        "#3. filter out langauge = english only\n",
        "cleaned_df = cleaned_df.filter(cleaned_df[\"language\"]==\"en\")\n",
        "cleaned_df = cleaned_df.filter(cleaned_df[\"usercreatedts\"] >= \"2009-01-01\")\n",
        "\n",
        "cleaned_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PsuQFKu47EEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af855678-d40d-45f6-d6f3-926ffb90b356"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109226"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "cleaned_df_count = cleaned_df.count()\n",
        "cleaned_df_count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "date_arr_august = [ \"0802\", \"0803\", \"0804\", \"0805\", \"0806\", \"0807\", \"0808\", \"0809\",\"0810\", \"0811\", \"0812\", \"0813\", \"0814\", \"0815\", \"0816\", \"0817\", \"0818\"]"
      ],
      "metadata": {
        "id": "1i90KFUkPi3S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCbblSe518Du",
        "outputId": "149e1380-8fc9-44ad-da7e-2f0c636f1134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0802 - 111897\n",
            "0803 - 114068\n",
            "0804 - 115988\n",
            "0805 - 117758\n",
            "0806 - 119826\n",
            "0807 - 121866\n",
            "0808 - 122572\n",
            "0809 - 122945\n",
            "0810 - 123615\n",
            "0811 - 124211\n",
            "0812 - 125335\n",
            "0813 - 125806\n",
            "0814 - 126104\n",
            "0815 - 126505\n",
            "0816 - 126973\n",
            "0817 - 127437\n",
            "0818 - 127977\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkFiles\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "url = \"https://databootcamps3bucket.s3.us-west-2.amazonaws.com/ua_war/UkraineWar\"\n",
        "\n",
        "for day in date_arr_august:\n",
        "      #load the data from aws\n",
        "      aws_url = f\"{url}/{day}_UATweets.csv.gz\"\n",
        "      spark.sparkContext.addFile(aws_url)\n",
        "      temp_df = spark.read.option(\"delimiter\", \",\").option(\"encoding\", \"UTF-8\").option(\"multiLine\", True).option(\"escape\", '\"').csv(SparkFiles.get(f\"{day}_UATweets.csv.gz\"),  header=True, inferSchema=True)\n",
        "      \n",
        "      #keep count number of columns to determine which if else block it will hit\n",
        "      temp_count = len(temp_df.columns)\n",
        "\n",
        "      #change columns from string to year:month:day date format\n",
        "      temp_df = temp_df.withColumn(\"usercreatedts\",to_date(\"usercreatedts\"))\n",
        "      temp_df = temp_df.withColumn(\"tweetcreatedts\",to_date(\"tweetcreatedts\"))\n",
        "      temp_df = temp_df.withColumn(\"extractedts\",to_date(\"extractedts\"))\n",
        "\n",
        "      #filter out data for english only \n",
        "      temp_df = temp_df.filter(temp_df[\"language\"]==\"en\")\n",
        "      #filter out usercreated after 2009 \n",
        "      temp_df = temp_df.filter(temp_df[\"usercreatedts\"] < \"2009-01-01\")\n",
        "\n",
        "      #fill in null values \n",
        "      temp_df_2 = temp_df.na.fill(\"<empty>\")\n",
        "\n",
        "      #some days the data columns has less columns then other days \n",
        "      if temp_count == 18:\n",
        "        temp_df_3 = temp_df_2.drop(\"userid\", \"_c0\", \"acctdesc\", \"location\", \"tweetid\", \"coordinates\")\n",
        "        temp_df_3 = temp_df_3.withColumn(\"is_retweet\", lit(None).cast('boolean')) \n",
        "        temp_df_3 = temp_df_3.withColumn(\"is_quote_status\", lit(None).cast('boolean')) \n",
        "\n",
        "      elif temp_count == 29:\n",
        "        temp_df_3 = temp_df_2.drop(\"userid\", \"_c0\", \"acctdesc\", \"location\", \"tweetid\", \"coordinates\", \"original_tweet_id\", \"original_tweet_userid\", \"original_tweet_username\", \"in_reply_to_status_id\", \"in_reply_to_screen_name\", 'in_reply_to_user_id', \"quoted_status_id\", \"quoted_status_username\", \"quoted_status_userid\")\n",
        "\n",
        "      else:\n",
        "        print(f\"Error on {day}_UATweets.csv.gz and column count {temp_count}\")\n",
        "\n",
        "      cleaned_df = cleaned_df.unionByName(temp_df_3)\n",
        "      print(f\"{day} - {cleaned_df.count()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UqTcDqfO2mK",
        "outputId": "d705cfab-df86-4a9a-aa22-a42192414043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+\n",
            "|    username|following|followers|totaltweets|usercreatedts|tweetcreatedts|retweetcount|                text|            hashtags|language|favorite_count|is_retweet|is_quote_status|extractedts|\n",
            "+------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+\n",
            "|   ORFMumbai|       51|     3362|      71331|   2011-09-08|    2022-08-01|           0|The #RussiaUkrain...|[{'text': 'Russia...|      en|             0|     false|          false| 2022-08-01|\n",
            "|For2000years|     2964|     4669|     119795|   2017-07-06|    2022-08-01|         560|Remember when #NA...|[{'text': 'NATO',...|      en|             0|      true|          false| 2022-08-01|\n",
            "| kaotiskhund|       49|        8|        112|   2021-04-04|    2022-08-01|           0|Hi #NATO , you ha...|[{'text': 'NATO',...|      en|             0|     false|          false| 2022-08-01|\n",
            "|   orfonline|      137|   114789|     315096|   2010-08-20|    2022-08-01|           0|The world is in d...|[{'text': 'Ukrain...|      en|             1|     false|          false| 2022-08-01|\n",
            "|     orfecon|       27|     3059|      13665|   2017-01-06|    2022-08-01|           0|Will the #sanctio...|[{'text': 'sancti...|      en|             0|     false|          false| 2022-08-01|\n",
            "+------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cleaned_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "G41nTWm_RY3v"
      },
      "outputs": [],
      "source": [
        "#add week column for \"tweetcreatedts\"\n",
        "cleaned_df = cleaned_df.withColumn(\"weekofyear\",weekofyear(\"tweetcreatedts\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFfdUvDHTBPp",
        "outputId": "9e92c099-4068-435a-bf38-9a36b9b5e23e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+----------+\n",
            "|    username|following|followers|totaltweets|usercreatedts|tweetcreatedts|retweetcount|                text|            hashtags|language|favorite_count|is_retweet|is_quote_status|extractedts|weekofyear|\n",
            "+------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+----------+\n",
            "|   ORFMumbai|       51|     3362|      71331|   2011-09-08|    2022-08-01|           0|The #RussiaUkrain...|[{'text': 'Russia...|      en|             0|     false|          false| 2022-08-01|        31|\n",
            "|For2000years|     2964|     4669|     119795|   2017-07-06|    2022-08-01|         560|Remember when #NA...|[{'text': 'NATO',...|      en|             0|      true|          false| 2022-08-01|        31|\n",
            "| kaotiskhund|       49|        8|        112|   2021-04-04|    2022-08-01|           0|Hi #NATO , you ha...|[{'text': 'NATO',...|      en|             0|     false|          false| 2022-08-01|        31|\n",
            "|   orfonline|      137|   114789|     315096|   2010-08-20|    2022-08-01|           0|The world is in d...|[{'text': 'Ukrain...|      en|             1|     false|          false| 2022-08-01|        31|\n",
            "|     orfecon|       27|     3059|      13665|   2017-01-06|    2022-08-01|           0|Will the #sanctio...|[{'text': 'sancti...|      en|             0|     false|          false| 2022-08-01|        31|\n",
            "+------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cleaned_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5rDA3KzXf9y",
        "outputId": "e68f04bb-bb00-466c-f7be-3bd0195fdb4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('username', 'string'),\n",
              " ('following', 'int'),\n",
              " ('followers', 'int'),\n",
              " ('totaltweets', 'int'),\n",
              " ('usercreatedts', 'date'),\n",
              " ('tweetcreatedts', 'date'),\n",
              " ('retweetcount', 'int'),\n",
              " ('text', 'string'),\n",
              " ('hashtags', 'string'),\n",
              " ('language', 'string'),\n",
              " ('favorite_count', 'int'),\n",
              " ('is_retweet', 'boolean'),\n",
              " ('is_quote_status', 'boolean'),\n",
              " ('extractedts', 'date'),\n",
              " ('weekofyear', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "cleaned_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgqRwUf5Piiy"
      },
      "source": [
        "### Connect to the AWS RDS instance and write each DataFrame to its table. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfJdnNYqPwYV",
        "outputId": "1b64214a-0a81-417f-c7e5-020c6c648295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter database passwordÂ·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "# Store environmental variable\n",
        "from getpass import getpass\n",
        "password = getpass('Enter database password')\n",
        "# Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://tweets.cnzbbvrrhst7.us-west-1.rds.amazonaws.com:5432/ua_data\"\n",
        "config = {\"user\":\"uatweets\", \n",
        "          \"password\": password, \n",
        "          \"driver\":\"org.postgresql.Driver\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "o4xuvfyFPwxS"
      },
      "outputs": [],
      "source": [
        "# Write review_id_df to table in RDS\n",
        "cleaned_df.write.jdbc(url=jdbc_url, table='tweets_table', mode=mode, properties=config)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "tweet_august.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}