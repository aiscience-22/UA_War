{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQPeAcH-160k",
        "outputId": "0854b393-f7db-4453-d0d6-27a7ca6cd2d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/88.7 kB 16%] [Connec\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 54.7 kB/88.7 kB 62%] [Waitin\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [1 InRelease 5\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r                                                                               \r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers]\r                                                                         \rGet:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [4 InRelease 14.2 kB/88.7 kB 16%] [Waiting for he\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [5 InRelease 6,945 B/74.6 kB 9%] [Waiting for hea\r                                                                               \rHit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [5 InRelease 28.7 kB/74.6 kB 38%] [Waiting for he\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \r0% [Waiting for headers] [Connecting to ppa.launchpad.net (185.125.190.52)]\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rIgn:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rHit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (165 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "# Importing the libraries needed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import scipy \n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import logging\n",
        "import os\n",
        "# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.2.2'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53UT8GZe21J_",
        "outputId": "1efdf278-a69c-4706-e0ee-892debf6051f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-30 03:28:53--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.16.jar.1’\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  5.53MB/s    in 0.2s    \n",
            "\n",
            "2022-08-30 03:28:53 (5.53 MB/s) - ‘postgresql-42.2.16.jar.1’ saved [1002883/1002883]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mfy8zMU72vjc"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"UA_War\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYrfA-bu20FQ",
        "outputId": "e9067e3b-fb97-4d59-9d0d-4aed572ff874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+---------------+--------------------+--------------------+---------+---------+-----------+--------------------+-------------------+--------------------+------------+--------------------+--------------------+--------+-----------+--------------+----------+-----------------+---------------------+-----------------------+---------------------+-------------------+-----------------------+---------------+----------------+--------------------+----------------------+--------------------+\n",
            "|_c0|             userid|       username|            acctdesc|            location|following|followers|totaltweets|       usercreatedts|            tweetid|      tweetcreatedts|retweetcount|                text|            hashtags|language|coordinates|favorite_count|is_retweet|original_tweet_id|original_tweet_userid|original_tweet_username|in_reply_to_status_id|in_reply_to_user_id|in_reply_to_screen_name|is_quote_status|quoted_status_id|quoted_status_userid|quoted_status_username|         extractedts|\n",
            "+---+-------------------+---------------+--------------------+--------------------+---------+---------+-----------+--------------------+-------------------+--------------------+------------+--------------------+--------------------+--------+-----------+--------------+----------+-----------------+---------------------+-----------------------+---------------------+-------------------+-----------------------+---------------+----------------+--------------------+----------------------+--------------------+\n",
            "|  0|1007291326554148864|TPGGamesandMore|TPG Games and TPG...|The Poletti Group...|      428|      952|        300|2018-06-14 15:59:...|1531787610854608898|2022-06-01 00:00:...|           0|#ArchaicAgeofDark...|[{'text': 'Archai...|      en|    <empty>|             0|     false|                0|                    0|                <empty>|                    0|                  0|                <empty>|          false|               0|                   0|               <empty>|2022-06-01 01:41:...|\n",
            "|  1| 966658642345897984|matthewsteakhou|En 2017, Matthieu...|       Cozes, France|      135|        6|       1723|2018-02-22 12:59:...|1531787611005759490|2022-06-01 00:00:...|           0|MATTHEW STEAKHOUS...|[{'text': 'restau...|      fr|    <empty>|             0|     false|                0|                    0|                <empty>|                    0|                  0|                <empty>|          false|               0|                   0|               <empty>|2022-06-01 01:41:...|\n",
            "|  2|           50687619|    CommTimesSC|The Community Tim...|        Florence, SC|     1816|      497|        446|2009-06-25 16:12:...|1531787611337068544|2022-06-01 00:00:...|           0|#dailymotivation ...|[{'text': 'dailym...|      en|    <empty>|             0|     false|                0|                    0|                <empty>|                    0|                  0|                <empty>|          false|               0|                   0|               <empty>|2022-06-01 01:41:...|\n",
            "|  3|1372541310150848515|     MissfreshL|Missfresh is an i...|       Beijing,China|      129|       75|        187|2021-03-18 13:33:...|1531787611978625027|2022-06-01 00:00:...|           0|Still remember ou...|[{'text': 'innova...|      en|    <empty>|             3|     false|                0|                    0|                <empty>|                    0|                  0|                <empty>|          false|               0|                   0|               <empty>|2022-06-01 03:26:...|\n",
            "|  4|1459941962686083074|  FunkyRaccoons|The Algovengers h...|             <empty>|     1735|     1341|       3010|2021-11-14 17:51:...|1531787611978846209|2022-06-01 00:00:...|           0|⚽️Algovenger Worl...|[{'text': 'USA', ...|      en|    <empty>|             1|     false|                0|                    0|                <empty>|                    0|                  0|                <empty>|          false|               0|                   0|               <empty>|2022-06-01 01:41:...|\n",
            "+---+-------------------+---------------+--------------------+--------------------+---------+---------+-----------+--------------------+-------------------+--------------------+------------+--------------------+--------------------+--------+-----------+--------------+----------+-----------------+---------------------+-----------------------+---------------------+-------------------+-----------------------+---------------+----------------+--------------------+----------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#import data from aws s3 bucket for 1 day. This will be the starting dataframe to populate DB\n",
        "\n",
        "from pyspark import SparkFiles\n",
        "start_date = \"0601\"\n",
        "\n",
        "url = f\"https://databootcamps3bucket.s3.us-west-2.amazonaws.com/ua_war/UkraineWar/{start_date}_UATweets.csv.gz\"\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "df_start_date = spark.read.option(\"delimiter\", \",\").option(\"encoding\", \"UTF-8\").option(\"multiLine\", True).option(\"escape\", '\"').csv(SparkFiles.get(f\"{start_date}_UATweets.csv.gz\"),  header=True, inferSchema=True)\n",
        "\n",
        "# df.show(truncate=False) \n",
        "df_start_date_2 = df_start_date.na.fill(\"<empty>\")\n",
        "\n",
        "df_start_date_2.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwCpQsor2vnS",
        "outputId": "956af2f8-f6f2-4867-b28f-08d651edb900"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('_c0', 'int'),\n",
              " ('userid', 'bigint'),\n",
              " ('username', 'string'),\n",
              " ('acctdesc', 'string'),\n",
              " ('location', 'string'),\n",
              " ('following', 'int'),\n",
              " ('followers', 'int'),\n",
              " ('totaltweets', 'int'),\n",
              " ('usercreatedts', 'string'),\n",
              " ('tweetid', 'bigint'),\n",
              " ('tweetcreatedts', 'string'),\n",
              " ('retweetcount', 'int'),\n",
              " ('text', 'string'),\n",
              " ('hashtags', 'string'),\n",
              " ('language', 'string'),\n",
              " ('coordinates', 'string'),\n",
              " ('favorite_count', 'int'),\n",
              " ('is_retweet', 'boolean'),\n",
              " ('original_tweet_id', 'bigint'),\n",
              " ('original_tweet_userid', 'bigint'),\n",
              " ('original_tweet_username', 'string'),\n",
              " ('in_reply_to_status_id', 'bigint'),\n",
              " ('in_reply_to_user_id', 'bigint'),\n",
              " ('in_reply_to_screen_name', 'string'),\n",
              " ('is_quote_status', 'boolean'),\n",
              " ('quoted_status_id', 'bigint'),\n",
              " ('quoted_status_userid', 'bigint'),\n",
              " ('quoted_status_username', 'string'),\n",
              " ('extractedts', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#see what the datatypes for df_8018 \n",
        "df_start_date.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ba5yU10j4S9u",
        "outputId": "37ee3635-7d26-4d46-f84c-c7df1ddc6402"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#use this to determine which type of drop is needed. Also not all all dates have same number of columns \n",
        "len(df_start_date.columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkFiles\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "#use this to determine which type of drop is needed. Also not all all dates have same number of columns \n",
        "df_start_date_count = len(df_start_date.columns)\n",
        "if df_start_date_count == 18:\n",
        "  df_start_date_2 = df_start_date_2.withColumn(\"is_retweet\", lit(None).cast('boolean')) \n",
        "  df_start_date_2 = df_start_date_2.withColumn(\"is_quote_status\", lit(None).cast('boolean')) \n",
        "\n",
        "len(df_start_date_2.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfJBYkO5VQA6",
        "outputId": "da2bcc93-a0ff-4891-fadd-48dd7bb92d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJWMS6ji65Lu",
        "outputId": "01e5957d-820a-4945-b1af-b24300cc18e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+\n",
            "| username|following|followers|totaltweets|usercreatedts|tweetcreatedts|retweetcount|                text|            hashtags|language|favorite_count|is_retweet|is_quote_status|extractedts|\n",
            "+---------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+\n",
            "|PSUdotcom|     1322|    46599|      81896|   2008-11-06|    2022-06-01|           2|Assassins Creed O...|[{'text': 'Assass...|      en|            11|     false|          false| 2022-06-01|\n",
            "|  hk_kure|      544|       72|       4044|   2008-07-25|    2022-06-01|        2540|Russian soldiers ...|[{'text': 'Ukrain...|      en|             0|      true|          false| 2022-06-01|\n",
            "|  DawgOnU|     1032|      247|      15636|   2008-11-09|    2022-06-01|           6|I didn't actually...|[{'text': 'Russia...|      en|             0|      true|          false| 2022-06-01|\n",
            "| Flyin18T|    28584|    34008|     755115|   2008-10-15|    2022-06-01|           0|#News A blast fro...|[{'text': 'News',...|      en|             0|     false|          false| 2022-06-01|\n",
            "|  pacofrg|       69|        3|       1133|   2008-07-03|    2022-06-01|         350|russian tank has ...|[{'text': 'Ukrain...|      en|             0|      true|          false| 2022-06-01|\n",
            "+---------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "#1. Drop Uncessary Columns using the data set as a starting point. \n",
        "cleaned_df = df_start_date_2.drop(\"userid\", \"_c0\", \"acctdesc\", \"location\", \"tweetid\", \"coordinates\", \"original_tweet_id\", \"original_tweet_userid\", \"original_tweet_username\", \"in_reply_to_status_id\", \"in_reply_to_screen_name\", 'in_reply_to_user_id', \"quoted_status_id\", \"quoted_status_username\", \"quoted_status_userid\")\n",
        "\n",
        "#2. change columns from string to year:month:day date format\n",
        "cleaned_df = cleaned_df.withColumn(\"usercreatedts\",to_date(\"usercreatedts\"))\n",
        "cleaned_df = cleaned_df.withColumn(\"tweetcreatedts\",to_date(\"tweetcreatedts\"))\n",
        "cleaned_df = cleaned_df.withColumn(\"extractedts\",to_date(\"extractedts\"))\n",
        "\n",
        "#3. filter out langauge = english only\n",
        "cleaned_df = cleaned_df.filter(cleaned_df[\"language\"]==\"en\")\n",
        "cleaned_df = cleaned_df.filter(cleaned_df[\"usercreatedts\"] < \"2009-01-01\")\n",
        "\n",
        "cleaned_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsuQFKu47EEF",
        "outputId": "b2c86822-5615-48e4-b3f8-0561bd84428e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3585"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "cleaned_df_count = cleaned_df.count()\n",
        "cleaned_df_count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "date_arr_june = [ \"0602\", \"0603\", \"0604\", \"0605\", \"0606_to_08\", \"0609\",\"0610\", \"0611\", \"0612\", \"0613\", \"0614\", \"0615\", \"0616\", \"0617\", \"0618\", \"0619\", \"0620\", \"0621\", \"0622\", \"0623\", \"0624\", \"0625\", \"0626\", \"0627\", \"0628\", \"0629\", \"0630\"]"
      ],
      "metadata": {
        "id": "g4-dhRXSPL2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCbblSe518Du",
        "outputId": "0c6b0438-7554-4601-fd66-ad1a05769633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0602 - 6762\n",
            "0603 - 10311\n",
            "0604 - 13259\n",
            "0605 - 16394\n",
            "0606_to_08 - 26390\n",
            "0609 - 29660\n",
            "0610 - 33222\n",
            "0611 - 36476\n",
            "0612 - 39498\n",
            "0613 - 42753\n",
            "0614 - 46103\n",
            "0615 - 49288\n",
            "0616 - 52943\n",
            "0617 - 56195\n",
            "0618 - 58793\n",
            "0619 - 61045\n",
            "0620 - 63627\n",
            "0621 - 66146\n",
            "0622 - 69157\n",
            "0623 - 72385\n",
            "0624 - 75056\n",
            "0625 - 77238\n",
            "0626 - 80070\n",
            "0627 - 83200\n",
            "0628 - 86502\n",
            "0629 - 89279\n",
            "0630 - 91817\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkFiles\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "url = \"https://databootcamps3bucket.s3.us-west-2.amazonaws.com/ua_war/UkraineWar\"\n",
        "\n",
        "for day in date_arr_june:\n",
        "      #load the data from aws\n",
        "      aws_url = f\"{url}/{day}_UATweets.csv.gz\"\n",
        "      spark.sparkContext.addFile(aws_url)\n",
        "      temp_df = spark.read.option(\"delimiter\", \",\").option(\"encoding\", \"UTF-8\").option(\"multiLine\", True).option(\"escape\", '\"').csv(SparkFiles.get(f\"{day}_UATweets.csv.gz\"),  header=True, inferSchema=True)\n",
        "      \n",
        "      #keep count number of columns to determine which if else block it will hit\n",
        "      temp_count = len(temp_df.columns)\n",
        "\n",
        "      #change columns from string to year:month:day date format\n",
        "      temp_df = temp_df.withColumn(\"usercreatedts\",to_date(\"usercreatedts\"))\n",
        "      temp_df = temp_df.withColumn(\"tweetcreatedts\",to_date(\"tweetcreatedts\"))\n",
        "      temp_df = temp_df.withColumn(\"extractedts\",to_date(\"extractedts\"))\n",
        "\n",
        "      #filter out data for english only \n",
        "      temp_df = temp_df.filter(temp_df[\"language\"]==\"en\")\n",
        "      #filter out usercreated after 2009 \n",
        "      temp_df = temp_df.filter(temp_df[\"usercreatedts\"] < \"2009-01-01\")\n",
        "\n",
        "      #fill in null values \n",
        "      temp_df_2 = temp_df.na.fill(\"<empty>\")\n",
        "\n",
        "      #some days the data columns has less columns then other days \n",
        "      if temp_count == 18:\n",
        "        temp_df_3 = temp_df_2.drop(\"userid\", \"_c0\", \"acctdesc\", \"location\", \"tweetid\", \"coordinates\")\n",
        "        temp_df_3 = temp_df_3.withColumn(\"is_retweet\", lit(None).cast('boolean')) \n",
        "        temp_df_3 = temp_df_3.withColumn(\"is_quote_status\", lit(None).cast('boolean')) \n",
        "\n",
        "      elif temp_count == 29:\n",
        "        temp_df_3 = temp_df_2.drop(\"userid\", \"_c0\", \"acctdesc\", \"location\", \"tweetid\", \"coordinates\", \"original_tweet_id\", \"original_tweet_userid\", \"original_tweet_username\", \"in_reply_to_status_id\", \"in_reply_to_screen_name\", 'in_reply_to_user_id', \"quoted_status_id\", \"quoted_status_username\", \"quoted_status_userid\")\n",
        "\n",
        "      else:\n",
        "        print(f\"Error on {day}_UATweets.csv.gz and column count {temp_count}\")\n",
        "\n",
        "      cleaned_df = cleaned_df.unionByName(temp_df_3)\n",
        "      print(f\"{day} - {cleaned_df.count()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UqTcDqfO2mK",
        "outputId": "dc3fc7c1-2ff1-4714-a473-d0ad7abfdef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+\n",
            "| username|following|followers|totaltweets|usercreatedts|tweetcreatedts|retweetcount|                text|            hashtags|language|favorite_count|is_retweet|is_quote_status|extractedts|\n",
            "+---------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+\n",
            "|PSUdotcom|     1322|    46599|      81896|   2008-11-06|    2022-06-01|           2|Assassins Creed O...|[{'text': 'Assass...|      en|            11|     false|          false| 2022-06-01|\n",
            "|  hk_kure|      544|       72|       4044|   2008-07-25|    2022-06-01|        2540|Russian soldiers ...|[{'text': 'Ukrain...|      en|             0|      true|          false| 2022-06-01|\n",
            "|  DawgOnU|     1032|      247|      15636|   2008-11-09|    2022-06-01|           6|I didn't actually...|[{'text': 'Russia...|      en|             0|      true|          false| 2022-06-01|\n",
            "| Flyin18T|    28584|    34008|     755115|   2008-10-15|    2022-06-01|           0|#News A blast fro...|[{'text': 'News',...|      en|             0|     false|          false| 2022-06-01|\n",
            "|  pacofrg|       69|        3|       1133|   2008-07-03|    2022-06-01|         350|russian tank has ...|[{'text': 'Ukrain...|      en|             0|      true|          false| 2022-06-01|\n",
            "+---------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cleaned_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G41nTWm_RY3v"
      },
      "outputs": [],
      "source": [
        "#add week column for \"tweetcreatedts\"\n",
        "cleaned_df = cleaned_df.withColumn(\"weekofyear\",weekofyear(\"tweetcreatedts\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFfdUvDHTBPp",
        "outputId": "62c73ce3-9db2-4765-f668-efc92325c3f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+----------+\n",
            "| username|following|followers|totaltweets|usercreatedts|tweetcreatedts|retweetcount|                text|            hashtags|language|favorite_count|is_retweet|is_quote_status|extractedts|weekofyear|\n",
            "+---------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+----------+\n",
            "|PSUdotcom|     1322|    46599|      81896|   2008-11-06|    2022-06-01|           2|Assassins Creed O...|[{'text': 'Assass...|      en|            11|     false|          false| 2022-06-01|        22|\n",
            "|  hk_kure|      544|       72|       4044|   2008-07-25|    2022-06-01|        2540|Russian soldiers ...|[{'text': 'Ukrain...|      en|             0|      true|          false| 2022-06-01|        22|\n",
            "|  DawgOnU|     1032|      247|      15636|   2008-11-09|    2022-06-01|           6|I didn't actually...|[{'text': 'Russia...|      en|             0|      true|          false| 2022-06-01|        22|\n",
            "| Flyin18T|    28584|    34008|     755115|   2008-10-15|    2022-06-01|           0|#News A blast fro...|[{'text': 'News',...|      en|             0|     false|          false| 2022-06-01|        22|\n",
            "|  pacofrg|       69|        3|       1133|   2008-07-03|    2022-06-01|         350|russian tank has ...|[{'text': 'Ukrain...|      en|             0|      true|          false| 2022-06-01|        22|\n",
            "+---------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+----------+---------------+-----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cleaned_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5rDA3KzXf9y",
        "outputId": "6c9eb939-a9ce-46a4-f781-dd015ff630ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('username', 'string'),\n",
              " ('following', 'int'),\n",
              " ('followers', 'int'),\n",
              " ('totaltweets', 'int'),\n",
              " ('usercreatedts', 'date'),\n",
              " ('tweetcreatedts', 'date'),\n",
              " ('retweetcount', 'int'),\n",
              " ('text', 'string'),\n",
              " ('hashtags', 'string'),\n",
              " ('language', 'string'),\n",
              " ('favorite_count', 'int'),\n",
              " ('is_retweet', 'boolean'),\n",
              " ('is_quote_status', 'boolean'),\n",
              " ('extractedts', 'date'),\n",
              " ('weekofyear', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "cleaned_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgqRwUf5Piiy"
      },
      "source": [
        "### Connect to the AWS RDS instance and write each DataFrame to its table. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfJdnNYqPwYV",
        "outputId": "2be260e8-88d8-44aa-969b-b4a07f1902ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter database password··········\n"
          ]
        }
      ],
      "source": [
        "# Store environmental variable\n",
        "from getpass import getpass\n",
        "password = getpass('Enter database password')\n",
        "# Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://tweets.cnzbbvrrhst7.us-west-1.rds.amazonaws.com:5432/ua_data\"\n",
        "config = {\"user\":\"uatweets\", \n",
        "          \"password\": password, \n",
        "          \"driver\":\"org.postgresql.Driver\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4xuvfyFPwxS"
      },
      "outputs": [],
      "source": [
        "# Write review_id_df to table in RDS\n",
        "cleaned_df.write.jdbc(url=jdbc_url, table='tweets_table', mode=mode, properties=config)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": " tweet_june.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}