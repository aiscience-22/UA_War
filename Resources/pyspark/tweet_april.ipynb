{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQPeAcH-160k",
        "outputId": "09ef67c2-e40c-4c6b-e3ff-a87714838f8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:4 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r                                                                               \rHit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "# Importing the libraries needed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import scipy \n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import logging\n",
        "import os\n",
        "# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.2.2'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53UT8GZe21J_",
        "outputId": "bf8b90e1-7f46-48bd-ea44-460583b0affa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-08-30 01:30:52--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: â€˜postgresql-42.2.16.jarâ€™\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  5.19MB/s    in 0.2s    \n",
            "\n",
            "2022-08-30 01:30:52 (5.19 MB/s) - â€˜postgresql-42.2.16.jarâ€™ saved [1002883/1002883]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Mfy8zMU72vjc"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"UA_War\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYrfA-bu20FQ",
        "outputId": "9fffdfdb-4562-4ae3-e285-ae835b8f9c05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-------------------+---------------+--------------------+--------------------+---------+---------+-----------+--------------------+-------------------+--------------------+------------+--------------------+--------------------+--------+-----------+--------------+--------------------+\n",
            "|_c0|             userid|       username|            acctdesc|            location|following|followers|totaltweets|       usercreatedts|            tweetid|      tweetcreatedts|retweetcount|                text|            hashtags|language|coordinates|favorite_count|         extractedts|\n",
            "+---+-------------------+---------------+--------------------+--------------------+---------+---------+-----------+--------------------+-------------------+--------------------+------------+--------------------+--------------------+--------+-----------+--------------+--------------------+\n",
            "|  0|           16882774|        Yaniela|Animal lover, sup...|              Hawaii|     1158|      392|      88366|2008-10-21 07:34:...|1509681950042198030|2022-04-01 00:00:...|        3412|âš¡The Ukrainian Ai...|                  []|      en|    <empty>|             0|2022-04-01 00:44:...|\n",
            "|  1|         3205296069|       gregffff|             <empty>|             <empty>|      122|      881|      99853|2015-04-25 11:24:...|1509681950151348229|2022-04-01 00:00:...|         100|Chernihiv oblast....|[{'text': 'russia...|      en|    <empty>|             0|2022-04-01 00:09:...|\n",
            "|  2|1235940869812809728|ThanapornThon17|à¹€à¸¥à¹ˆà¸™à¹„à¸§à¹‚à¸­à¸¥à¸´à¸™\\nà¸žà¸¹à¸”à¸ ...|             <empty>|      231|       72|       5481|2020-03-06 14:52:...|1509681950683926556|2022-04-01 00:00:...|           9|America ðŸ‡ºðŸ‡¸ is p...|[{'text': 'Russia...|      en|    <empty>|             0|2022-04-01 00:09:...|\n",
            "|  3|1347985375566966784| I_Protest_2021|01000001 01101110...|International Web...|      399|      377|        301|2021-01-09 19:15:...|1509681951116046336|2022-04-01 00:00:...|         573|JUST IN: #Anonymo...|[{'text': 'Anonym...|      en|    <empty>|             0|2022-04-01 00:31:...|\n",
            "|  4|1505394816636846083|   Marsh_Win_01|ðŸŒ¿@Pickaw @TWITTE...|      Hunter Account|      158|       25|       8982|2022-03-20 04:04:...|1509681951304990720|2022-04-01 00:00:...|         190|***PUBLIC MINT NO...|                  []|      en|    <empty>|             0|2022-04-01 00:09:...|\n",
            "+---+-------------------+---------------+--------------------+--------------------+---------+---------+-----------+--------------------+-------------------+--------------------+------------+--------------------+--------------------+--------+-----------+--------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#import data from aws s3 bucket for 1 day. This will be the starting dataframe to populate DB\n",
        "\n",
        "from pyspark import SparkFiles\n",
        "start_date = \"0401\"\n",
        "\n",
        "url = f\"https://databootcamps3bucket.s3.us-west-2.amazonaws.com/ua_war/UkraineWar/{start_date}_UATweets.csv.gz\"\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "df_start_date = spark.read.option(\"delimiter\", \",\").option(\"encoding\", \"UTF-8\").option(\"multiLine\", True).option(\"escape\", '\"').csv(SparkFiles.get(f\"{start_date}_UATweets.csv.gz\"),  header=True, inferSchema=True)\n",
        "\n",
        "# df.show(truncate=False) \n",
        "df_start_date_2 = df_start_date.na.fill(\"<empty>\")\n",
        "\n",
        "df_start_date_2.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwCpQsor2vnS",
        "outputId": "3d7fd914-880d-4923-9036-d1954c04a64e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('_c0', 'int'),\n",
              " ('userid', 'bigint'),\n",
              " ('username', 'string'),\n",
              " ('acctdesc', 'string'),\n",
              " ('location', 'string'),\n",
              " ('following', 'int'),\n",
              " ('followers', 'int'),\n",
              " ('totaltweets', 'int'),\n",
              " ('usercreatedts', 'string'),\n",
              " ('tweetid', 'bigint'),\n",
              " ('tweetcreatedts', 'string'),\n",
              " ('retweetcount', 'int'),\n",
              " ('text', 'string'),\n",
              " ('hashtags', 'string'),\n",
              " ('language', 'string'),\n",
              " ('coordinates', 'string'),\n",
              " ('favorite_count', 'int'),\n",
              " ('extractedts', 'string')]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#see what the datatypes for df_8018 \n",
        "df_start_date.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ba5yU10j4S9u",
        "outputId": "25b4d910-e300-4bb3-d9c4-d75d33d1d225"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#use this to determine which type of drop is needed. Also not all all dates have same number of columns \n",
        "len(df_start_date.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfJBYkO5VQA6",
        "outputId": "6f5a70e9-ee56-4290-8a82-4606e7484516"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark import SparkFiles\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "#use this to determine which type of drop is needed. Also not all all dates have same number of columns \n",
        "df_start_date_count = len(df_start_date.columns)\n",
        "if df_start_date_count == 18:\n",
        "  df_start_date_2 = df_start_date_2.withColumn(\"is_retweet\", lit(None).cast('boolean')) \n",
        "  df_start_date_2 = df_start_date_2.withColumn(\"is_quote_status\", lit(None).cast('boolean')) \n",
        "\n",
        "len(df_start_date_2.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJWMS6ji65Lu",
        "outputId": "ebd593ee-bfe8-44a0-a2ed-7b291175d049"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+\n",
            "|   username|following|followers|totaltweets|usercreatedts|tweetcreatedts|retweetcount|                text|            hashtags|language|favorite_count|extractedts|is_retweet|is_quote_status|\n",
            "+-----------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+\n",
            "|    Yaniela|     1158|      392|      88366|   2008-10-21|    2022-04-01|        3412|âš¡The Ukrainian Ai...|                  []|      en|             0| 2022-04-01|      null|           null|\n",
            "|   livemint|       70|  2033266|     394746|   2008-11-27|    2022-04-01|           2|India's purchase ...|[{'text': 'Russia...|      en|             7| 2022-04-01|      null|           null|\n",
            "|   helchose|     2693|      818|      76574|   2008-08-06|    2022-04-01|           5|Russia24 is now r...|                  []|      en|             0| 2022-04-01|      null|           null|\n",
            "|BowmanNancy|     5654|     7306|      82319|   2008-04-13|    2022-04-01|           0|@RobbieGramer Wit...|[{'text': 'Ukrain...|      en|             0| 2022-04-01|      null|           null|\n",
            "|    sigil66|     1163|      675|      15364|   2008-12-02|    2022-04-01|           0|Given that there ...|[{'text': 'Russia...|      en|             0| 2022-04-01|      null|           null|\n",
            "+-----------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "#1. Drop Uncessary Columns using the data set of 08-18-2022 as a starting point. \n",
        "cleaned_df = df_start_date_2.drop(\"userid\", \"_c0\", \"acctdesc\", \"location\", \"tweetid\", \"coordinates\", \"original_tweet_id\", \"original_tweet_userid\", \"original_tweet_username\", \"in_reply_to_status_id\", \"in_reply_to_screen_name\", 'in_reply_to_user_id', \"quoted_status_id\", \"quoted_status_username\", \"quoted_status_userid\")\n",
        "\n",
        "#2. change columns from string to year:month:day date format\n",
        "cleaned_df = cleaned_df.withColumn(\"usercreatedts\",to_date(\"usercreatedts\"))\n",
        "cleaned_df = cleaned_df.withColumn(\"tweetcreatedts\",to_date(\"tweetcreatedts\"))\n",
        "cleaned_df = cleaned_df.withColumn(\"extractedts\",to_date(\"extractedts\"))\n",
        "\n",
        "#3. filter out langauge = english only\n",
        "cleaned_df = cleaned_df.filter(cleaned_df[\"language\"]==\"en\")\n",
        "cleaned_df = cleaned_df.filter(cleaned_df[\"usercreatedts\"] < \"2009-01-01\")\n",
        "\n",
        "cleaned_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsuQFKu47EEF",
        "outputId": "f37ee3bd-2c8a-4c59-b20d-24776dfa30a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6199"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_df_count = cleaned_df.count()\n",
        "cleaned_df_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jeiWZxAePLqp"
      },
      "outputs": [],
      "source": [
        "date_arr_april = [ \"0402\", \"0403\", \"0404\", \"0405\", \"0406\", \"0407\", \"0408\", \"0409\",\"0410\", \"0411\", \"0412\", \"0413\", \"0414\", \"0415\", \"0416\", \"0417\", \"0418\", \"0419\", \"0420\", \"0421\", \"0422\", \"0423\", \"0424\", \"0425\", \"0426\", \"0427\", \"0428\", \"0429\", \"0430\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCbblSe518Du",
        "outputId": "91a2ded7-1206-4d47-a2c0-281f31e0802f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0402 - 12510\n",
            "0403 - 19637\n",
            "0404 - 26082\n",
            "0405 - 32584\n",
            "0406 - 39004\n",
            "0407 - 44668\n",
            "0408 - 50255\n",
            "0409 - 56154\n",
            "0410 - 61791\n",
            "0411 - 67322\n",
            "0412 - 72976\n",
            "0413 - 78634\n",
            "0414 - 83715\n",
            "0415 - 89036\n",
            "0416 - 93866\n",
            "0417 - 98592\n",
            "0418 - 103709\n",
            "0419 - 109379\n",
            "0420 - 114341\n",
            "0421 - 119197\n",
            "0422 - 123636\n",
            "0423 - 128379\n",
            "0424 - 133181\n",
            "0425 - 137330\n",
            "0426 - 142114\n",
            "0427 - 146439\n",
            "0428 - 150627\n",
            "0429 - 154985\n",
            "0430 - 159841\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkFiles\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "url = \"https://databootcamps3bucket.s3.us-west-2.amazonaws.com/ua_war/UkraineWar\"\n",
        "\n",
        "for day in date_arr_april:\n",
        "      #load the data from aws\n",
        "      aws_url = f\"{url}/{day}_UATweets.csv.gz\"\n",
        "      spark.sparkContext.addFile(aws_url)\n",
        "      temp_df = spark.read.option(\"delimiter\", \",\").option(\"encoding\", \"UTF-8\").option(\"multiLine\", True).option(\"escape\", '\"').csv(SparkFiles.get(f\"{day}_UATweets.csv.gz\"),  header=True, inferSchema=True)\n",
        "      \n",
        "      #keep count number of columns to determine which if else block it will hit\n",
        "      temp_count = len(temp_df.columns)\n",
        "\n",
        "      #change columns from string to year:month:day date format\n",
        "      temp_df = temp_df.withColumn(\"usercreatedts\",to_date(\"usercreatedts\"))\n",
        "      temp_df = temp_df.withColumn(\"tweetcreatedts\",to_date(\"tweetcreatedts\"))\n",
        "      temp_df = temp_df.withColumn(\"extractedts\",to_date(\"extractedts\"))\n",
        "\n",
        "      #filter out data for english only \n",
        "      temp_df = temp_df.filter(temp_df[\"language\"]==\"en\")\n",
        "      #filter out usercreated before 2009\n",
        "      temp_df = temp_df.filter(temp_df[\"usercreatedts\"] < \"2009-01-01\")\n",
        "\n",
        "      #fill in null values \n",
        "      temp_df_2 = temp_df.na.fill(\"<empty>\")\n",
        "\n",
        "      #some days the data columns has less columns then other days \n",
        "      if temp_count == 18:\n",
        "        temp_df_3 = temp_df_2.drop(\"userid\", \"_c0\", \"acctdesc\", \"location\", \"tweetid\", \"coordinates\")\n",
        "        temp_df_3 = temp_df_3.withColumn(\"is_retweet\", lit(None).cast('boolean')) \n",
        "        temp_df_3 = temp_df_3.withColumn(\"is_quote_status\", lit(None).cast('boolean')) \n",
        "\n",
        "      elif temp_count == 29:\n",
        "        temp_df_3 = temp_df_2.drop(\"userid\", \"_c0\", \"acctdesc\", \"location\", \"tweetid\", \"coordinates\", \"original_tweet_id\", \"original_tweet_userid\", \"original_tweet_username\", \"in_reply_to_status_id\", \"in_reply_to_screen_name\", 'in_reply_to_user_id', \"quoted_status_id\", \"quoted_status_username\", \"quoted_status_userid\")\n",
        "\n",
        "      else:\n",
        "        print(f\"Error on {day}_UATweets.csv.gz and column count {temp_count}\")\n",
        "\n",
        "      cleaned_df = cleaned_df.unionByName(temp_df_3)\n",
        "      print(f\"{day} - {cleaned_df.count()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UqTcDqfO2mK",
        "outputId": "910f6651-bcbb-4b72-f392-02b3d60269cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+\n",
            "|   username|following|followers|totaltweets|usercreatedts|tweetcreatedts|retweetcount|                text|            hashtags|language|favorite_count|extractedts|is_retweet|is_quote_status|\n",
            "+-----------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+\n",
            "|    Yaniela|     1158|      392|      88366|   2008-10-21|    2022-04-01|        3412|âš¡The Ukrainian Ai...|                  []|      en|             0| 2022-04-01|      null|           null|\n",
            "|   livemint|       70|  2033266|     394746|   2008-11-27|    2022-04-01|           2|India's purchase ...|[{'text': 'Russia...|      en|             7| 2022-04-01|      null|           null|\n",
            "|   helchose|     2693|      818|      76574|   2008-08-06|    2022-04-01|           5|Russia24 is now r...|                  []|      en|             0| 2022-04-01|      null|           null|\n",
            "|BowmanNancy|     5654|     7306|      82319|   2008-04-13|    2022-04-01|           0|@RobbieGramer Wit...|[{'text': 'Ukrain...|      en|             0| 2022-04-01|      null|           null|\n",
            "|    sigil66|     1163|      675|      15364|   2008-12-02|    2022-04-01|           0|Given that there ...|[{'text': 'Russia...|      en|             0| 2022-04-01|      null|           null|\n",
            "+-----------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cleaned_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "G41nTWm_RY3v"
      },
      "outputs": [],
      "source": [
        "#add week column for \"tweetcreatedts\"\n",
        "cleaned_df = cleaned_df.withColumn(\"weekofyear\",weekofyear(\"tweetcreatedts\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFfdUvDHTBPp",
        "outputId": "c740aef2-d9b1-435c-ff6f-c2a7b6e9cebc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+----------+\n",
            "|   username|following|followers|totaltweets|usercreatedts|tweetcreatedts|retweetcount|                text|            hashtags|language|favorite_count|extractedts|is_retweet|is_quote_status|weekofyear|\n",
            "+-----------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+----------+\n",
            "|    Yaniela|     1158|      392|      88366|   2008-10-21|    2022-04-01|        3412|âš¡The Ukrainian Ai...|                  []|      en|             0| 2022-04-01|      null|           null|        13|\n",
            "|   livemint|       70|  2033266|     394746|   2008-11-27|    2022-04-01|           2|India's purchase ...|[{'text': 'Russia...|      en|             7| 2022-04-01|      null|           null|        13|\n",
            "|   helchose|     2693|      818|      76574|   2008-08-06|    2022-04-01|           5|Russia24 is now r...|                  []|      en|             0| 2022-04-01|      null|           null|        13|\n",
            "|BowmanNancy|     5654|     7306|      82319|   2008-04-13|    2022-04-01|           0|@RobbieGramer Wit...|[{'text': 'Ukrain...|      en|             0| 2022-04-01|      null|           null|        13|\n",
            "|    sigil66|     1163|      675|      15364|   2008-12-02|    2022-04-01|           0|Given that there ...|[{'text': 'Russia...|      en|             0| 2022-04-01|      null|           null|        13|\n",
            "+-----------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cleaned_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5rDA3KzXf9y",
        "outputId": "03678483-4a1e-471d-d713-e6ce50c2bbcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('username', 'string'),\n",
              " ('following', 'int'),\n",
              " ('followers', 'int'),\n",
              " ('totaltweets', 'int'),\n",
              " ('usercreatedts', 'date'),\n",
              " ('tweetcreatedts', 'date'),\n",
              " ('retweetcount', 'int'),\n",
              " ('text', 'string'),\n",
              " ('hashtags', 'string'),\n",
              " ('language', 'string'),\n",
              " ('favorite_count', 'int'),\n",
              " ('extractedts', 'date'),\n",
              " ('is_retweet', 'boolean'),\n",
              " ('is_quote_status', 'boolean'),\n",
              " ('weekofyear', 'int')]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgqRwUf5Piiy"
      },
      "source": [
        "### Connect to the AWS RDS instance and write each DataFrame to its table. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfJdnNYqPwYV",
        "outputId": "dda63126-1086-4b4a-a636-0d0e9e3085ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter database passwordÂ·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "# Store environmental variable\n",
        "from getpass import getpass\n",
        "password = getpass('Enter database password')\n",
        "# Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://tweets.cnzbbvrrhst7.us-west-1.rds.amazonaws.com:5432/ua_data\"\n",
        "config = {\"user\":\"uatweets\", \n",
        "          \"password\": password, \n",
        "          \"driver\":\"org.postgresql.Driver\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "o4xuvfyFPwxS"
      },
      "outputs": [],
      "source": [
        "# Write review_id_df to table in RDS\n",
        "cleaned_df.write.jdbc(url=jdbc_url, table='tweets_table', mode=mode, properties=config)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "tweet_april.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
