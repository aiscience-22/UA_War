{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQPeAcH-160k",
        "outputId": "5e0e5d79-54f2-4c0d-c172-3c9e3664d477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\r                                                                               \rHit:2 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\r0% [1 InRelease gpgv 15.9 kB] [Connecting to archive.ubuntu.com (91.189.91.39)]\r                                                                               \rHit:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 15.9 kB] [Connecting to archive.ubuntu.com (91.189.91.39)]\r                                                                               \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Fetched 252 kB in 3s (93.2 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "# Importing the libraries needed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import scipy \n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import logging\n",
        "import os\n",
        "# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.2.2'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53UT8GZe21J_",
        "outputId": "0274611a-bd1f-4b30-8463-2019f52b9c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-30 03:00:56--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: ‚Äòpostgresql-42.2.16.jar.2‚Äô\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  1.59MB/s    in 0.6s    \n",
            "\n",
            "2022-08-30 03:00:57 (1.59 MB/s) - ‚Äòpostgresql-42.2.16.jar.2‚Äô saved [1002883/1002883]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Mfy8zMU72vjc"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"UA_War\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYrfA-bu20FQ",
        "outputId": "f06f28d8-991d-4bc6-e5a4-008e268bf4d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+--------------+--------------------+--------------------+---------+---------+-----------+--------------------+-------------------+-------------------+------------+--------------------+--------------------+--------+-----------+--------------+--------------------+\n",
            "|   _c0|    userid|      username|            acctdesc|            location|following|followers|totaltweets|       usercreatedts|            tweetid|     tweetcreatedts|retweetcount|                text|            hashtags|language|coordinates|favorite_count|         extractedts|\n",
            "+------+----------+--------------+--------------------+--------------------+---------+---------+-----------+--------------------+-------------------+-------------------+------------+--------------------+--------------------+--------+-----------+--------------+--------------------+\n",
            "|149212|  37334464|DownandOut1489|Because He lives ...|             <empty>|      914|      759|      40561|2009-05-03 01:43:...|1498447926531887104|2022-03-01 00:00:00|           0|It‚Äôs all a game a...|[{'text': 'corona...|      en|    <empty>|             0|2022-03-01 00:02:...|\n",
            "|149213|  17710740|           dna|Follow us for new...|               India|       24|  2264852|     647718|2008-11-28 15:39:...|1498447927009693697|2022-03-01 00:00:00|           0|.@peta urges gove...|[{'text': 'Ukrain...|      en|    <empty>|             0|2022-03-01 00:02:...|\n",
            "|149214| 318485865|BlakeAlldredge|Follower of Jesus...|               Texas|      734|      241|      10044|2011-06-16 15:25:...|1498447927022264320|2022-03-01 00:00:00|           0|Instead of talkin...|[{'text': 'Ukrain...|      en|    <empty>|             0|2022-03-01 00:02:...|\n",
            "|149215|3541217477|   jethom33545|             <empty>|             <empty>|      114|        6|        700|2015-09-04 04:47:...|1498447927236255754|2022-03-01 00:00:00|        1684|‚úäüèºüá∫üá¶ \\n#Ukrain...|[{'text': 'Ukrain...|     und|    <empty>|             0|2022-03-01 00:02:...|\n",
            "|149216|  14115646|        donnyd|MD. My daughter, ...|Stoney Creek, Ont...|     1269|     1668|      22199|2008-03-10 17:27:...|1498447927622176768|2022-03-01 00:00:00|       20587|Moscow undergroun...|[{'text': 'Ukrain...|      en|    <empty>|             0|2022-03-01 00:02:...|\n",
            "+------+----------+--------------+--------------------+--------------------+---------+---------+-----------+--------------------+-------------------+-------------------+------------+--------------------+--------------------+--------+-----------+--------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#import data from aws s3 bucket for 1 day. This will be the starting dataframe to populate DB\n",
        "\n",
        "from pyspark import SparkFiles\n",
        "start_date = \"0301\"\n",
        "\n",
        "url = f\"https://databootcamps3bucket.s3.us-west-2.amazonaws.com/ua_war/UkraineWar/{start_date}_UATweets.csv.gz\"\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "df_start_date = spark.read.option(\"delimiter\", \",\").option(\"encoding\", \"UTF-8\").option(\"multiLine\", True).option(\"escape\", '\"').csv(SparkFiles.get(f\"{start_date}_UATweets.csv.gz\"),  header=True, inferSchema=True)\n",
        "\n",
        "# df.show(truncate=False) \n",
        "df_start_date_2 = df_start_date.na.fill(\"<empty>\")\n",
        "\n",
        "df_start_date_2.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwCpQsor2vnS",
        "outputId": "2209a246-7944-47b5-ece9-8e6e3dac4798"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('_c0', 'int'),\n",
              " ('userid', 'bigint'),\n",
              " ('username', 'string'),\n",
              " ('acctdesc', 'string'),\n",
              " ('location', 'string'),\n",
              " ('following', 'int'),\n",
              " ('followers', 'int'),\n",
              " ('totaltweets', 'int'),\n",
              " ('usercreatedts', 'string'),\n",
              " ('tweetid', 'bigint'),\n",
              " ('tweetcreatedts', 'string'),\n",
              " ('retweetcount', 'int'),\n",
              " ('text', 'string'),\n",
              " ('hashtags', 'string'),\n",
              " ('language', 'string'),\n",
              " ('coordinates', 'string'),\n",
              " ('favorite_count', 'int'),\n",
              " ('extractedts', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#see what the datatypes for df_8018 \n",
        "df_start_date.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ba5yU10j4S9u",
        "outputId": "cfc79b26-370b-4d0a-b927-1bba37db12ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#use this to determine which type of drop is needed. Also not all all dates have same number of columns \n",
        "len(df_start_date.columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkFiles\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "#use this to determine which type of drop is needed. Also not all all dates have same number of columns \n",
        "df_start_date_count = len(df_start_date.columns)\n",
        "if df_start_date_count == 18:\n",
        "  df_start_date_2 = df_start_date_2.withColumn(\"is_retweet\", lit(None).cast('boolean')) \n",
        "  df_start_date_2 = df_start_date_2.withColumn(\"is_quote_status\", lit(None).cast('boolean')) \n",
        "\n",
        "len(df_start_date_2.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfJBYkO5VQA6",
        "outputId": "b7156e3d-52b0-4718-a09d-732544063821"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJWMS6ji65Lu",
        "outputId": "5086091c-7cad-45b6-e2d3-609967b7d590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+\n",
            "|     username|following|followers|totaltweets|usercreatedts|tweetcreatedts|retweetcount|                text|            hashtags|language|favorite_count|extractedts|is_retweet|is_quote_status|\n",
            "+-------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+\n",
            "|          dna|       24|  2264852|     647718|   2008-11-28|    2022-03-01|           0|.@peta urges gove...|[{'text': 'Ukrain...|      en|             0| 2022-03-01|      null|           null|\n",
            "|       donnyd|     1269|     1668|      22199|   2008-03-10|    2022-03-01|       20587|Moscow undergroun...|[{'text': 'Ukrain...|      en|             0| 2022-03-01|      null|           null|\n",
            "|     ABCNews4|     6527|    97364|     201941|   2008-06-13|    2022-03-01|           0|Ukrainian forces ...|[{'text': 'Russia...|      en|             0| 2022-03-01|      null|           null|\n",
            "|txwikinger_ea|     2857|     2145|     161723|   2008-04-24|    2022-03-01|         147|#Ukraine: We aren...|[{'text': 'Ukrain...|      en|             0| 2022-03-01|      null|           null|\n",
            "|     livemint|       70|  2027629|     390236|   2008-11-27|    2022-03-01|           0|#MintPrimer | The...|[{'text': 'MintPr...|      en|             1| 2022-03-01|      null|           null|\n",
            "+-------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "#1. Drop Uncessary Columns using the data set of 08-18-2022 as a starting point. \n",
        "cleaned_df = df_start_date_2.drop(\"userid\", \"_c0\", \"acctdesc\", \"location\", \"tweetid\", \"coordinates\", \"original_tweet_id\", \"original_tweet_userid\", \"original_tweet_username\", \"in_reply_to_status_id\", \"in_reply_to_screen_name\", 'in_reply_to_user_id', \"quoted_status_id\", \"quoted_status_username\", \"quoted_status_userid\")\n",
        "\n",
        "#2. change columns from string to year:month:day date format\n",
        "cleaned_df = cleaned_df.withColumn(\"usercreatedts\",to_date(\"usercreatedts\"))\n",
        "cleaned_df = cleaned_df.withColumn(\"tweetcreatedts\",to_date(\"tweetcreatedts\"))\n",
        "cleaned_df = cleaned_df.withColumn(\"extractedts\",to_date(\"extractedts\"))\n",
        "\n",
        "#3. filter out langauge = english only\n",
        "cleaned_df = cleaned_df.filter(cleaned_df[\"language\"]==\"en\")\n",
        "cleaned_df = cleaned_df.filter(cleaned_df[\"usercreatedts\"] < \"2009-01-01\")\n",
        "\n",
        "cleaned_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsuQFKu47EEF",
        "outputId": "e81e96d0-32ac-4ca0-b944-b27faecf03cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5819"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "cleaned_df_count = cleaned_df.count()\n",
        "cleaned_df_count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "date_arr_march = [\"0302\", \"0303\", \"0304\", \"0305\", \"0306\", \"0307\", \"0308\", \"0309\",\"0310\", \"0311\", \"0312\", \"0313\", \"0314\", \"0315\", \"0316\", \"0317\", \"0318\", \"0319\", \"0320\", \"0321\", \"0322\", \"0323\", \"0324\", \"0325\", \"0326\", \"0327_to_28\", \"0329\", \"0330\", \"0331\"]"
      ],
      "metadata": {
        "id": "tD_UIt3WPLdK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reverse_march_arr = date_arr_march.reverse()\n",
        "# reverse_march_arr\n",
        "\n",
        "reverse_march_arr = date_arr_march[::-1] "
      ],
      "metadata": {
        "id": "W0HiB64vdRHu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reverse_march_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXgI2A6rfBOZ",
        "outputId": "eafb9275-a510-4395-8c95-c43dfa8c27de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0331', '0330', '0329', '0327_to_28', '0326', '0325', '0324', '0323', '0322', '0321', '0320', '0319', '0318', '0317', '0316', '0315', '0314', '0313', '0312', '0311', '0310', '0309', '0308', '0307', '0306', '0305', '0304', '0303', '0302']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCbblSe518Du",
        "outputId": "3befcdff-0af1-4907-c16e-1e5561842d67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0331 - 11220\n",
            "0330 - 16574\n",
            "0329 - 22351\n",
            "0327_to_28 - 34582\n",
            "0326 - 41512\n",
            "0325 - 48762\n",
            "0324 - 55175\n",
            "0323 - 62027\n",
            "0322 - 68907\n",
            "0321 - 77402\n",
            "0320 - 84582\n",
            "0319 - 91720\n",
            "0318 - 100011\n",
            "0317 - 108256\n",
            "0316 - 115944\n",
            "0315 - 124412\n",
            "0314 - 131508\n",
            "0313 - 138839\n",
            "0312 - 145564\n",
            "0311 - 152725\n",
            "0310 - 160400\n",
            "0309 - 168261\n",
            "0308 - 177108\n",
            "0307 - 187120\n",
            "0306 - 196191\n",
            "0305 - 204519\n",
            "0304 - 211474\n",
            "0303 - 217086\n",
            "0302 - 223023\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkFiles\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "url = \"https://databootcamps3bucket.s3.us-west-2.amazonaws.com/ua_war/UkraineWar\"\n",
        "\n",
        "for day in reverse_march_arr:\n",
        "      #load the data from aws\n",
        "      aws_url = f\"{url}/{day}_UATweets.csv.gz\"\n",
        "      spark.sparkContext.addFile(aws_url)\n",
        "      temp_df = spark.read.option(\"delimiter\", \",\").option(\"encoding\", \"UTF-8\").option(\"multiLine\", True).option(\"escape\", '\"').csv(SparkFiles.get(f\"{day}_UATweets.csv.gz\"),  header=True, inferSchema=True)\n",
        "      \n",
        "      #keep count number of columns to determine which if else block it will hit\n",
        "      temp_count = len(temp_df.columns)\n",
        "\n",
        "      #change columns from string to year:month:day date format\n",
        "      temp_df = temp_df.withColumn(\"usercreatedts\",to_date(\"usercreatedts\"))\n",
        "      temp_df = temp_df.withColumn(\"tweetcreatedts\",to_date(\"tweetcreatedts\"))\n",
        "      temp_df = temp_df.withColumn(\"extractedts\",to_date(\"extractedts\"))\n",
        "\n",
        "      #filter out data for english only \n",
        "      temp_df = temp_df.filter(temp_df[\"language\"]==\"en\")\n",
        "      #filter out usercreated after 2009 \n",
        "      temp_df = temp_df.filter(temp_df[\"usercreatedts\"] < \"2009-01-01\")\n",
        "\n",
        "      #fill in null values \n",
        "      temp_df_2 = temp_df.na.fill(\"<empty>\")\n",
        "\n",
        "      #some days the data columns has less columns then other days \n",
        "      if temp_count == 18:\n",
        "        temp_df_3 = temp_df_2.drop(\"userid\", \"_c0\", \"acctdesc\", \"location\", \"tweetid\", \"coordinates\")\n",
        "        temp_df_3 = temp_df_3.withColumn(\"is_retweet\", lit(None).cast('boolean')) \n",
        "        temp_df_3 = temp_df_3.withColumn(\"is_quote_status\", lit(None).cast('boolean')) \n",
        "\n",
        "      elif temp_count == 29:\n",
        "        temp_df_3 = temp_df_2.drop(\"userid\", \"_c0\", \"acctdesc\", \"location\", \"tweetid\", \"coordinates\", \"original_tweet_id\", \"original_tweet_userid\", \"original_tweet_username\", \"in_reply_to_status_id\", \"in_reply_to_screen_name\", 'in_reply_to_user_id', \"quoted_status_id\", \"quoted_status_username\", \"quoted_status_userid\")\n",
        "\n",
        "      else:\n",
        "        print(f\"Error on {day}_UATweets.csv.gz and column count {temp_count}\")\n",
        "\n",
        "      cleaned_df = cleaned_df.unionByName(temp_df_3)\n",
        "      print(f\"{day} - {cleaned_df.count()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UqTcDqfO2mK",
        "outputId": "b4210962-ef6c-40b2-a810-1f9f1d3fe941"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+\n",
            "|     username|following|followers|totaltweets|usercreatedts|tweetcreatedts|retweetcount|                text|            hashtags|language|favorite_count|extractedts|is_retweet|is_quote_status|\n",
            "+-------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+\n",
            "|          dna|       24|  2264852|     647718|   2008-11-28|    2022-03-01|           0|.@peta urges gove...|[{'text': 'Ukrain...|      en|             0| 2022-03-01|      null|           null|\n",
            "|       donnyd|     1269|     1668|      22199|   2008-03-10|    2022-03-01|       20587|Moscow undergroun...|[{'text': 'Ukrain...|      en|             0| 2022-03-01|      null|           null|\n",
            "|     ABCNews4|     6527|    97364|     201941|   2008-06-13|    2022-03-01|           0|Ukrainian forces ...|[{'text': 'Russia...|      en|             0| 2022-03-01|      null|           null|\n",
            "|txwikinger_ea|     2857|     2145|     161723|   2008-04-24|    2022-03-01|         147|#Ukraine: We aren...|[{'text': 'Ukrain...|      en|             0| 2022-03-01|      null|           null|\n",
            "|     livemint|       70|  2027629|     390236|   2008-11-27|    2022-03-01|           0|#MintPrimer | The...|[{'text': 'MintPr...|      en|             1| 2022-03-01|      null|           null|\n",
            "+-------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cleaned_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "G41nTWm_RY3v"
      },
      "outputs": [],
      "source": [
        "#add week column for \"tweetcreatedts\"\n",
        "cleaned_df = cleaned_df.withColumn(\"weekofyear\",weekofyear(\"tweetcreatedts\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFfdUvDHTBPp",
        "outputId": "7e4b551f-19de-4c58-ef8f-0873364c4c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+----------+\n",
            "|     username|following|followers|totaltweets|usercreatedts|tweetcreatedts|retweetcount|                text|            hashtags|language|favorite_count|extractedts|is_retweet|is_quote_status|weekofyear|\n",
            "+-------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+----------+\n",
            "|          dna|       24|  2264852|     647718|   2008-11-28|    2022-03-01|           0|.@peta urges gove...|[{'text': 'Ukrain...|      en|             0| 2022-03-01|      null|           null|         9|\n",
            "|       donnyd|     1269|     1668|      22199|   2008-03-10|    2022-03-01|       20587|Moscow undergroun...|[{'text': 'Ukrain...|      en|             0| 2022-03-01|      null|           null|         9|\n",
            "|     ABCNews4|     6527|    97364|     201941|   2008-06-13|    2022-03-01|           0|Ukrainian forces ...|[{'text': 'Russia...|      en|             0| 2022-03-01|      null|           null|         9|\n",
            "|txwikinger_ea|     2857|     2145|     161723|   2008-04-24|    2022-03-01|         147|#Ukraine: We aren...|[{'text': 'Ukrain...|      en|             0| 2022-03-01|      null|           null|         9|\n",
            "|     livemint|       70|  2027629|     390236|   2008-11-27|    2022-03-01|           0|#MintPrimer | The...|[{'text': 'MintPr...|      en|             1| 2022-03-01|      null|           null|         9|\n",
            "+-------------+---------+---------+-----------+-------------+--------------+------------+--------------------+--------------------+--------+--------------+-----------+----------+---------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cleaned_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5rDA3KzXf9y",
        "outputId": "467d8cd8-f9fe-4890-e2da-e73b8aab3425"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('username', 'string'),\n",
              " ('following', 'int'),\n",
              " ('followers', 'int'),\n",
              " ('totaltweets', 'int'),\n",
              " ('usercreatedts', 'date'),\n",
              " ('tweetcreatedts', 'date'),\n",
              " ('retweetcount', 'int'),\n",
              " ('text', 'string'),\n",
              " ('hashtags', 'string'),\n",
              " ('language', 'string'),\n",
              " ('favorite_count', 'int'),\n",
              " ('extractedts', 'date'),\n",
              " ('is_retweet', 'boolean'),\n",
              " ('is_quote_status', 'boolean'),\n",
              " ('weekofyear', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "cleaned_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6XwDhvUyaa6",
        "outputId": "5f62e033-4961-4435-e7ae-423be5417d18"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "223023"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgqRwUf5Piiy"
      },
      "source": [
        "### Connect to the AWS RDS instance and write each DataFrame to its table. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfJdnNYqPwYV",
        "outputId": "de5448af-ab63-4b2a-d420-5b307ccbf579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter database password¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ],
      "source": [
        "# Store environmental variable\n",
        "from getpass import getpass\n",
        "password = getpass('Enter database password')\n",
        "# Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://tweets.cnzbbvrrhst7.us-west-1.rds.amazonaws.com:5432/ua_data\"\n",
        "config = {\"user\":\"uatweets\", \n",
        "          \"password\": password, \n",
        "          \"driver\":\"org.postgresql.Driver\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "o4xuvfyFPwxS"
      },
      "outputs": [],
      "source": [
        "# Write review_id_df to table in RDS\n",
        "cleaned_df.write.jdbc(url=jdbc_url, table='tweets_table', mode=mode, properties=config)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "tweet_march.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}